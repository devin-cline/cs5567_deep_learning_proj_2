{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "hASLpyncBmvt"
   },
   "outputs": [],
   "source": [
    "!pip install -U portalocker>=2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3IIK5kzHGH0"
   },
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "_aWMlQ33ByRO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "jOCzfnBvB_bQ"
   },
   "outputs": [],
   "source": [
    "# Transformations --> this is a \"pre-processing step\" that's typical for image processing methods\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL image or numpy.ndarray to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize data to range [-1, 1]\n",
    "])\n",
    "# This dataset is already \"sorted\" as part of the import method, but no \"validation\" set has been selected in this case\n",
    "# Loading the FashionMNIST dataset\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Training and Testing loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "jZk_FS9JCLOH"
   },
   "outputs": [],
   "source": [
    "# Mapping the labels for the MNIST dataset -- later we'll see that this using the \"keras to_categorical\" method as discussed in class\n",
    "labels_map = {\n",
    "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n",
    "    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "ykrRIGSdCMu5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAKSCAYAAABMVtaZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQXUlEQVR4nO3deXiV9Zn/8TuE7CEsCQmBJAQMi4osshUENxSsVeqC4jatSselYx2nY3W008tWxVrr2G1ara3Vat0orrWXWrVYRUAQBFRUNtlCICEQsq/w+2NG5/Ln9/OFc0xykvN9v65r/pjPc905T07Oc87dI/f9JBw8ePCgAQAAIO71iPUJAAAAoHPQ+AEAAASCxg8AACAQNH4AAACBoPEDAAAIBI0fAABAIGj8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASCxq8LaGpqshtvvNEGDhxoaWlpNnnyZHvllVdifVpAXHn99dctISHB+X/Lli2L9ekBcePSSy+V11pCQoKVlpbG+hSD1jPWJ4D/uUgWLlxo1113nQ0bNsweeughO/30023RokU2bdq0WJ8eEFeuvfZamzhx4ueykpKSGJ0NEH+uvPJKO+WUUz6XHTx40K666iorLi62QYMGxejMYEbjF3PLly+3J554wn7605/a9ddfb2Zm3/jGN2zUqFF2ww032JIlS2J8hkB8mT59us2ZMyfWpwHErSlTptiUKVM+ly1evNjq6+vt4osvjtFZ4VP8p94YW7hwoSUmJtoVV1zxWZaammrz5s2zpUuX2vbt22N4dkB8qqmpsdbW1lifBhCMxx57zBISEuyiiy6K9akEj8Yvxt59910bPny4ZWVlfS6fNGmSmZmtXr06BmcFxK/LLrvMsrKyLDU11U466SR75513Yn1KQFxraWmxBQsW2NSpU624uDjWpxM8/lNvjJWVlVl+fv4X8k+znTt3dvYpAXEpOTnZzj33XDv99NMtJyfH1q1bZ3fffbdNnz7dlixZYuPGjYv1KQJx6eWXX7bKykr+M28XQeMXYw0NDZaSkvKFPDU19bPjAL68qVOn2tSpUz/7/2fPnm1z5syx0aNH20033WQvvfRSDM8OiF+PPfaYJSUl2fnnnx/rU4Hxn3pjLi0tzZqamr6QNzY2fnYcQMcoKSmxr3/967Zo0SJra2uL9ekAcae2ttaee+45mzVrlmVnZ8f6dGA0fjGXn59vZWVlX8g/zQYOHNjZpwQEpbCw0Jqbm62uri7WpwLEnWeffZZp3i6Gxi/Gxo4da+vXr7fq6urP5W+//fZnxwF0nM2bN1tqaqplZmbG+lSAuPPoo49aZmamzZ49O9angv9F4xdjc+bMsba2Nrv//vs/y5qamuzBBx+0yZMnW2FhYQzPDogfFRUVX8jWrFljzz//vM2cOdN69ODtEGhPFRUV9uqrr9rZZ59t6enpsT4d/C+GO2Js8uTJdt5559lNN91k5eXlVlJSYn/84x9ty5Yt9sADD8T69IC4MXfuXEtLS7OpU6dabm6urVu3zu6//35LT0+3O++8M9anB8SdJ5980lpbW/nPvF1MwsGDBw/G+iRC19jYaD/4wQ/sT3/6k+3bt89Gjx5tt912m82aNSvWpwbEjV/+8pf26KOP2saNG626utr69+9vM2bMsFtuuYVbtgEdYMqUKbZ582bbuXOnJSYmxvp08L9o/AAAAALBP2oBAAAIBI0fAABAIGj8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASCxg8AACAQh33njoSEhI48jy5j5syZ8ti4ceOc+auvviprVq5c+aXP6XBccMEFzvwrX/mKrHn66aed+RtvvNEu59QddMU1lqFcawgL1xrQOQ51rfGNHwAAQCBo/AAAAAJB4wcAABAIGj8AAIBAJBw8zH9x25X/EezcuXOd+UUXXSRrRo0a5cx79jzseZfPZGRkyGPZ2dnOvKWlRda0tbU586SkJFmzf//+iB9n3759zjw5OVnWrF271pk//vjjsmbBggXyWKzxD86BzsG1BnQOhjsAAABgZjR+AAAAwaDxAwAACASNHwAAQCBo/AAAAAJB4wcAABCIbrPO5bbbbpPHzj33XGdeWVkpa+rr6515bW2trFGrWQoKCmSNWs3i057Pte85WLdunTP3/T7p6enOvF+/frLmz3/+szP/4Q9/KGs6CysmgM7BtQZ0Dta5AAAAwMxo/AAAAIJB4wcAABAIGj8AAIBA0PgBAAAEostN9Y4aNcqZP/XUU7Jm27Ztzry1tVXWqN/H93s2NDQ486OPPlrWJCUlOfPm5uaIz61HD92nq2nbJUuWRPw4PXv2lDUpKSkRn1thYaEzv+CCC2TN6tWr5bH2xKQh0Dm41oDOwVQvAAAAzIzGDwAAIBg0fgAAAIGg8QMAAAgEjR8AAEAgaPwAAAACofd2xMg111wTcU1iYmLENS0tLc48mvH+jz76SB6bNGmSM/eNWzc1NTnzvn37ypq1a9c688bGRlnTq1cvZ+57PtUxX41a9TJv3jxZ853vfEceAwAA0eEbPwAAgEDQ+AEAAASCxg8AACAQNH4AAACBoPEDAAAIRMLBw7xzdmfdzFpNyPqmRnft2uXMa2trZU1SUpIzb25uljVtbW3OvK6uTtbk5uY682HDhkV8bps2bZI1GzZscOa+SWA1bdva2ipr1Ougf//+siYvL08eU0pKSiKuiQY3jgc6B9ca0DkOda3xjR8AAEAgaPwAAAACQeMHAAAQCBo/AACAQND4AQAABILGDwAAIBA9Y/GgRUVF8tiBAweceUtLi6wZMGCAMy8vL5c1e/fudebp6emyRp2Db2XKvn37nPn69etljVqzsnPnTllTXFzszH2rZtR6mvr6ellTWFjozNXaGjOzhoYGZ+5b0aPWw1RUVMgaAADgxzd+AAAAgaDxAwAACASNHwAAQCBo/AAAAAJB4wcAABCImEz1Xn755fJYUlKSM29sbJQ1ffr0ceYTJ06UNStWrHDmvsnZ1NRUZ66mY83MkpOTnblvOrW5udmZ+6ahly9f7syHDx8ua9T0cFpamqwZP368M1dT0mZmtbW1zrxnT/3yu+KKK5z5/PnzZQ26l4SEBHlM3WRcvWbN9EYA9f5gpl/Pr732mqxRr1vf+0BnOdTN2SMRzXMNoOvjGz8AAIBA0PgBAAAEgsYPAAAgEDR+AAAAgaDxAwAACASNHwAAQCBiss7Ft5ZEKSwsjLjmvvvuk8dOOOEEZ65WtpiZJSYmOvOqqipZk5KSEnGNWsmwfft2WfPyyy8788mTJ8uaTZs2OfPjjz9e1jzyyCPO/JxzzpE1AwcOdObV1dWyZsiQIfIY4kNnrXM544wzZE1TU5M8prS2tkZc0558a5DUShnfmhe1QqulpSWyE0O35LsO21N7rhr6+te/Lo8999xz7fY4nSWa98Ivg2/8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASCxg8AACAQMZnqvfzyy+WxAQMGOPP/+I//kDU1NTXO/E9/+pOsueqqq5z5tm3bZE1mZqYzz8/PlzVqenfUqFGyRk0P19bWypqHHnrImW/ZskXWqAnm3r17y5pf/epXztw3oaumEO+8805ZU15eLo8hPqgpXDN9DfgmatX1Gc1GgGnTpsljixcvjvjntaf2nipmejd+qOlQ32RoR0yNRuK4446Tx6688kpn/sknn8iaDz74wJlv3LgxshOLUjQTur6/QTR/00PhGz8AAIBA0PgBAAAEgsYPAAAgEDR+AAAAgaDxAwAACASNHwAAQCASDh7mTHBn3ci5s6gVBu+//76sUSsmGhoaZE00qxeiuWm6qmlsbJQ1zc3NzvzYY4+VNf369ZPHuqNYrzJwibdrLRpq1ZDv9fzVr37VmZeUlMiaSy+91JnX1dXJmqKioojPrampSR5T1PXe1tYma9T7TVZWlqx54oknnPn8+fNlTXdcG+LCtdZ5fvKTnzjz7OxsWZOWlubM+/TpI2vuv/9+Z/7cc8/pk4uxaFbA+Byqhm/8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASCxg8AACAQMZnqVdOx0dao6VSfPXv2OPOysjJZU1VV5cx79ND9s7oRve9pV5N5anLX9/PUVJSZng7Mzc2VNUOHDpXHlOTk5Ige3yy65y0aTBp2vGgmQKOpGTx4sDP3XQMLFixw5ur1Z2aWkZHhzH1T9773iEj53gfU9LC6Bs3M3nvvPWd+9tlnR3Zi5n/t+p7TWIm3a6095efny2Njx4515pdccomsGT16tDNXn8VmZjU1Nc68uLg44prjjz9e1vg+i9qTmmBeuXKlrFHPtepHzJjqBQAAwP+i8QMAAAgEjR8AAEAgaPwAAAACQeMHAAAQCBo/AACAQPSMxYNGMzrd3qsAqqurI65RaxR8v08060LU40SzNkathvH9vNraWs/ZRS6adTuIHx1xk3GX/v37O/PU1FRZo9af+N5vGhoanHl6erqsqa+vd+a+1SxKNO+FvveOzMzMiH9eNI/TFUWzNijSn+U75nu+fO/dkfKt6Lrqqquc+SmnnCJrpkyZ4sw/+ugjWaNe675VQ4WFhc58y5YtskZ9HvtWpvz85z935g899JCsicYdd9zhzNUKGjOzG264wZnffPPNUZ9H97pKAQAAEDUaPwAAgEDQ+AEAAASCxg8AACAQNH4AAACBSDh4mONLsb6ZdTQTrT7r1q1z5r4JXTXt6nt8dcxX056TcT176sFtNWWlJh3NzI477riIz6E9J+faW1c4h/9frK+19taeU+otLS2y5uKLL3bmq1evljXLly935hUVFbJm9+7dztz3d1O/q28SWE071tXVyRr1/KhJZDN9w/tvfOMbsmbRokXO3Del3BWn+9Xfxfe3VO8ZnfVeMn78eHnsmmuucebHHHOMrBk6dKgzLy0tlTWbN2925vfdd5+sueSSS5y575pW18fIkSNlTVpamjNvbGyUNRkZGc68vLxc1nz44YfO3DdB3atXr4hyM7OcnBxnriaezQ79WuQbPwAAgEDQ+AEAAASCxg8AACAQNH4AAACBoPEDAAAIBI0fAABAIPSujzinxp076ybj7b2yQ61t8a1+6NevnzOP5sbxCINaleDjWyXSnjZt2uTMfasSzjrrLGc+e/ZsWTN9+nRnfsQRR8gatR5mz549sqZ///7O3Hd9qnVU+fn5skbdvN63BifSx++qOms1S2pqqjM/88wzZc3XvvY1Z37qqafKGnUN7Nu3T9Y888wzzryyslLWqJUlzz77rKxRq1F8r7Ps7GxnrlYqmenneuDAgbJGrWrzvd9NmTLFmftWqKnXlW+ljVrrdNJJJ8maQ+EbPwAAgEDQ+AEAAASCxg8AACAQNH4AAACBoPEDAAAIRLBTvermz/X19Z3y+NFMjUUzCex7HDWB17dv34gfx0edd2fd1Bxu0fxd2nNC94ILLpDHzjvvPGfum+ZbtGiRM1c3UzczW7ZsmTN/5ZVXZI3Sp08feey9995z5q2trbJG/X2amppkzbhx45z5nXfeKWtuuukmeUxR53bgwIGIf1ZX9JWvfEUemzBhgjMfNmyYrFETpVlZWZGdmJmtWrVKHlOTszt37pQ1xcXFznzo0KGyRk3BvvTSS7ImJSXFmScmJsqaqqoqZ64md33ntm3bNlmjrl01UWsW3QS7+l19n+3Nzc3OvKamJuLH/xTf+AEAAASCxg8AACAQNH4AAACBoPEDAAAIBI0fAABAIGj8AAAAAtFt1rlEs8rEJzMz05nv379f1vToEXmfrNYbtPcqE7UWwjf2rlZzqPH+aLX33w6Hz7cqIZp1BKeddpozv/7662XN9OnTnbnvWlOrCnyrhubOnevMt2zZImvGjx8vj0VKrZ4wM9u1a5czz8vLi/jn+W4cv3btWmcezcoWtX7DzL9SpjuZNGmSM7/xxhtlTUlJiTP3reZRK0YaGxtljVo55luZo67pgoKCiGsGDRoka9Tn5969e2VNUlKSM1e/p5lZfn6+M+/ZU7cu6vnxfQ5VVFQ48169eskaRf2eZvrcfL2Feq5963YOhW/8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASCxg8AACAQ3WaqN5qbf/smAHfs2OHMW1paZE0006lqWqezbmbumxZSN3/26d27tzP3TWi29wRzqHwTuuq16Zs0VBYsWCCPTZkyxZn3799f1vzgBz9w5rm5ubJm3rx5znz79u2yRk27FhUVyZqxY8c689WrV8uaaIwcOdKZb9iwQdao96IxY8bImokTJ0Z2YqZfV773KDVV2d2u9RUrVjjzc845R9aoSdNjjz1W1owYMcKZ+6a61XYF31S3mhKuq6uTNWoKdf369bIm0sc305P65eXlskZNQ1dXV0d8Dr7Xs/qc9H3mq2PRXAO+z2L1Oli2bFnEj/MpvvEDAAAIBI0fAABAIGj8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASi26xz8a0lUTeZPvLII2VNcnKyM/eNoyvRrMzwjXxHszZGiWaEffPmzbJGPadfZrQch0e9zqP1s5/9zJmfdtppsmbNmjXOvE+fPrLmH//4hzN/++23Zc2MGTOcuW81i1oL4btp+q9+9StnPn36dFmjqBU0Znothe+9Q636eP/992XNO++8I48p6nXV3q+3ruiYY46JuObDDz905i+88IKs8R0DOhvf+AEAAASCxg8AACAQNH4AAACBoPEDAAAIBI0fAABAIGIy1eubWlXTrtHc+FjdGNt3DtFM6EbDN6Ucze+qpnd9j6Nq1A3YzcyGDx/uzJnqbT8nnHCCM581a5asUTf5XrdunaxRP8/3+lPXVGJioqz53ve+58xvv/12WfP0008781tvvVXW7N+/35mXlpbKmt69e0f8OIsWLXLmc+fOlTXvvfeeM/dN3Tc1NUX0s8zMCgsLnfnYsWNljZo49r0O1N979+7dsqYrWr9+vTMvKSmRNSeeeKIz910D6u9cXV0ta9SGCd9rRh3zfa6pGt/ntPpdfZ8d6nF8z5uaLB88eLCsUefge22q59p3DbS0tDhz32euOuaryczMdOYrVqyQNYfCN34AAACBoPEDAAAIBI0fAABAIGj8AAAAAkHjBwAAEAgaPwAAgEAkHDzM3SG+0e6u6rHHHpPHjjrqKGdeVVUla9TN3n3j9dGIZp2L4huVV2sc+vbtK2vUepBLL700ovPqKtrzuW4v6lrLy8uTNQMGDIj4cYqKipx5QUGBrFGvmfr6elmj1qyoVQ1mZpWVlc587969skatZPBd0+oc+vTpI2vUeoUdO3bImmhkZWU5c7WCxsxs4MCBzjwlJUXW1NXVRVyjnrdt27bJGt9anVhpz8813yoTdX36atTzrz6HzKL7LFI/z/feqNbD+H6faFaZqDVV6hr0nYN6fzBr3zU40fA9b+o9d+PGjbLmUJ9rfOMHAAAQCBo/AACAQND4AQAABILGDwAAIBA0fgAAAIHoclO9asInmgmarVu3ymPl5eXOXE0RRXsOnUX9GX1/NzWx5JuyUhO/o0eP9pydm+9xOuu57k5TvUB3xrUGdA6megEAAGBmNH4AAADBoPEDAAAIBI0fAABAIGj8AAAAAkHjBwAAEAh9Z+AYSUxMdOa+9R7qxuRqZYuZHnf23SzZt+ol1tRaAt9Yt/pdfTXqhvfqb2BmtnPnTmfeFda5AAAQEr7xAwAACASNHwAAQCBo/AAAAAJB4wcAABAIGj8AAIBAdLmp3mhu5F1cXOzMU1JSZE19fb0zb2trkzXq3Nr7Rt++addI+aZjk5KSnHlTU5OsSU9Pd+ZFRUWyRk31AgCAzsU3fgAAAIGg8QMAAAgEjR8AAEAgaPwAAAACQeMHAAAQCBo/AACAQMTFOpecnBxn7luz0tLS4sx9q1QSExMjOzHT61Tac2WL7+f51tOoY76/gXqcvLw8z9m5+VbNAACA9sc3fgAAAIGg8QMAAAgEjR8AAEAgaPwAAAACQeMHAAAQiC431RvNpGffvn2deXNzs6xRk6uNjY2yRk3B+qaHFd9Ur/p50Tw3vgld9Ti+c1PT0Gqy2ieaCW4AABA9vvEDAAAIBI0fAABAIGj8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASiy61ziWbFxymnnOLMe/fuLWvUKpMBAwZE/Pi+dS5qNUo0v2c0a2PUChrfz9u+fbusyczMdObTpk2TNQ888IA8BgAAOg/f+AEAAASCxg8AACAQNH4AAACBoPEDAAAIBI0fAABAILrcVG80XnjhBWe+Zs0aWbNp0yZn7pu2bWlpceb19fWypqGhwZk3NjbKGkVN1JqZJSUlOfP09HRZk5ycHNHPMjMrKipy5qWlpbJGiWayGQAARI9v/AAAAAJB4wcAABAIGj8AAIBA0PgBAAAEgsYPAAAgEDR+AAAAgUg4yE4NAACAIPCNHwAAQCBo/AAAAAJB4wcAABAIGj8AAIBA0PgBAAAEgsYPAAAgEDR+AAAAgaDxAwAACASNHwAAQCBo/AAAAAJB4wcAABAIGj8AAIBA0PgBAAAEgsYPAAAgEDR+XcCGDRvsggsusIKCAktPT7eRI0farbfeavX19bE+NSBuvP7665aQkOD8v2XLlsX69IC4snLlSjvttNMsKyvLevXqZTNnzrTVq1fH+rRgZj1jfQKh2759u02aNMl69+5t11xzjfXr18+WLl1qt9xyi61cudKee+65WJ8iEFeuvfZamzhx4ueykpKSGJ0NEH9WrVpl06ZNs8LCQrvlllvswIED9pvf/MZOOOEEW758uY0YMSLWpxg0Gr8Ye+SRR6yqqsoWL15sRx99tJmZXXHFFXbgwAF7+OGHbd++fda3b98YnyUQP6ZPn25z5syJ9WkAcesHP/iBpaWl2dKlSy07O9vMzC655BIbPny43XzzzfbUU0/F+AzDxn/qjbHq6mozM8vLy/tcnp+fbz169LDk5ORYnBYQ12pqaqy1tTXWpwHEpTfffNNOOeWUz5o+s//5TDvhhBPshRdesNra2hieHWj8YuzEE080M7N58+bZ6tWrbfv27fbkk0/avffea9dee61lZGTE9gSBOHPZZZdZVlaWpaam2kknnWTvvPNOrE8JiCtNTU2Wlpb2hTw9Pd2am5vt/fffj8FZ4VP8p94YO+200+y2226zO+64w55//vnP8u9///t2++23x/DMgPiSnJxs5557rp1++umWk5Nj69ats7vvvtumT59uS5YssXHjxsX6FIG4MGLECFu2bJm1tbVZYmKimZk1Nzfb22+/bWZmpaWlsTy94NH4dQHFxcV2/PHH27nnnmvZ2dn217/+1e644w4bMGCAXXPNNbE+PSAuTJ061aZOnfrZ/z979mybM2eOjR492m666SZ76aWXYnh2QPz49re/bVdffbXNmzfPbrjhBjtw4IDdfvvtVlZWZmZmDQ0NMT7DsCUcPHjwYKxPImRPPPGEXX755bZ+/XorKCj4LL/ssstswYIFtm3bts/9OwkA7evCCy+0p59+2urr6z/7dgLAl/P973/ffvrTn1pLS4uZmU2YMMFmzZpl8+fPt2eeecbOOuus2J5gwPg3fjH2m9/8xsaNG/e5ps/sf76NqK+vt3fffTdGZwaEobCw0Jqbm62uri7WpwLEjfnz59vu3bvtzTfftLVr19qKFSvswIEDZmY2fPjwGJ9d2PhPvTG2e/du57qWT/9XEpOHQMfavHmzpaamWmZmZqxPBYgrffv2tWnTpn32/7/66qtWUFBgI0eOjOFZgW/8Ymz48OH27rvv2vr16z+XP/7449ajRw8bPXp0jM4MiC8VFRVfyNasWWPPP/+8zZw503r04O0Q6ChPPvmkrVixwq677jqutRjj3/jF2BtvvGEnn3yyZWdn2zXXXGPZ2dn2wgsv2Isvvmjf+ta37He/+12sTxGICyeffLKlpaXZ1KlTLTc319atW2f333+/JSUl2dKlS+3II4+M9SkCceGNN96wW2+91WbOnGnZ2dm2bNkye/DBB+3UU0+1v/zlL9azJ/+xMZZo/LqA5cuX2w9/+EN79913rbKy0oYMGWLf/OY37YYbbuACAdrJL3/5S3v00Udt48aNVl1dbf3797cZM2bYLbfcwi3bgHa0adMm+/a3v22rVq2ympqazz7Tvvvd73JTgi6Axg8AACAQ/Id2AACAQND4AQAABILGDwAAIBA0fgAAAIGg8QMAAAgEjR8AAEAgaPwAAAACcdjbgRMSEjryPLoFdZuZT288HQnfwtiBAwc6c9c9fT9VXV3tzBctWhTZiZlZYmKiPNbW1hbxz+vKuuIaS6616J6Drvi3xP/pin8frjXEo0Nda3zjBwAAEAgaPwAAgEDQ+AEAAASCxg8AACAQNH4AAACBSDh4mKNW3XH6SU3h+vh+z2gmWmfPnu3Mt27dKmvWrFkT8eMUFRU58+OPP17WvPrqq858165dsqY9J5u7AiYNEamUlBRnftNNN8maI444wplnZmbKmoyMDGd+zz33yJozzzzTmZ999tmyRr13tLa2yhr1GvVdT1xrQOdgqhcAAABmRuMHAAAQDBo/AACAQND4AQAABILGDwAAIBA0fgAAAIGIi3Uu0awYac+1JPPmzZPH3nrrLWf+0UcfRfw47e2ss85y5qtXr5Y1W7Zsifhxoln90Fm6wjn8/7rytRZrapWKmdmwYcOc+Yknnihr1Lqjuro6WVNbW+vMi4uLZY16namfZWaWmJjozH2roObMmePMH3jgAVkzf/58eaw9ca0BnYN1LgAAADAzGj8AAIBg0PgBAAAEgsYPAAAgEDR+AAAAgegZ6xPoSGoqzsysra3NmQ8cOFDWnHDCCc78r3/9q6zZtWuXM09OTpY1zc3N8piiflf1e5qZPfvss8581qxZsmbQoEHOXE0vm+kJIzVZbRbddDXix7/+678685EjR8qampoaZ15ZWSlr1LX75ptvyprNmzfLY7H24YcfOvOpU6fKmoyMDGfum2wG0H3xjR8AAEAgaPwAAAACQeMHAAAQCBo/AACAQND4AQAABILGDwAAIBAJBw/zztnR3Mw6mhUj6nF8p6nWgvhWggwePNiZz507V9bcdddd8pjSs6d7Y05ra2vEPysavr9bNDdNP/vss535gAEDZM29994b8eN01vPGjeO7pqFDhzpz3wqgjRs3dtTpxEQ072vXX3+9M1erqMzMXn31VWf+i1/8wnN2keNaAzrHoa41vvEDAAAIBI0fAABAIGj8AAAAAkHjBwAAEAgaPwAAgEB06FRve05MqSlPM7OWlhZnXlxcLGvOP/98Zx7N5K5v0tA3gRdPZs6cKY9NnjzZmd92220RP46aFDfzT4srTBqGLdbPdXu//v7whz8483HjxsmaBQsWOPPS0lJZ8/DDD0d2Ysa1BnQWpnoBAABgZjR+AAAAwaDxAwAACASNHwAAQCBo/AAAAAJB4wcAABAIvSOlHaiRYt8IvVrXoVa2mJllZ2c781NPPVXW/Nd//ZczT0pKkjVqbYtvdFqtc/HVtOeKAd+qGaW1tVUeU7/P3/72N1mzdetWZ65uKG9mdvfddzvzaFa2oPuJ5nWrrinftdYVV4x8GU1NTc58xIgRsub000935r/73e9kTb9+/Zz53r17PWeHeOf77IrmWisoKHDmFRUVskZdA12Zr+849thjnblvXd2h8I0fAABAIGj8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASiQ6d6Fd90j5oo9U35TZ8+3Zn7ptIUpkbb38cff+zMt23bJmveeOMNZ3788ce3yzmha1PT4/HG976mnoOsrCxZM2HCBGe+cuVKWTNy5Ehnnp+fL2sKCwudOVO98aO9J3QVNblrZvbNb37Tme/cuVPWvPTSS868ublZ1qhJ4Lq6OlmjnoPzzz9f1qhrt7q6WtasWbPGmb/44ouy5lD4xg8AACAQNH4AAACBoPEDAAAIBI0fAABAIGj8AAAAAkHjBwAAEIiYrHOJxtNPPy2PqZsVq1FwM7Pt27c78xdeeEHWVFZWOvOGhgZZs3XrVmfuGxNXN0BPSUmRNWoNTlFRkazJyclx5snJybLmuOOOc+YnnHCCrFGj94MGDZI1eXl5znzu3Lmy5sknn5THgHgxevRoeWzAgAHO/Bvf+IasUdf7xRdfLGvUigmVo/tpz5UtPuPHj5fHUlNTnfnQoUNlzbe//W1nnpSUJGvUWqXExERZ09LS4szVZ5eZXoO0dOlSWbNgwQJ5LFp84wcAABAIGj8AAIBA0PgBAAAEgsYPAAAgEDR+AAAAgYjJVG9aWpo89rOf/cyZjxs3TtaoGxyXlJTImilTpjjzOXPmyJr9+/c7c98N5Wtra52574bR6ljPnvrPpW4y7bsBtppkimbiWD2+mZ7MqqmpkTVVVVXO/Oqrr5Y1TPWiu1HXoJl+X7niiitkjZrEzMjIkDVqOtG3rWDmzJnO/KWXXpI1iH/RTAL7Nk+UlpY68+zsbFmjtkhkZWXJGnVMTcmbmeXm5jrz8vJyWaOuw5UrV8qajsA3fgAAAIGg8QMAAAgEjR8AAEAgaPwAAAACQeMHAAAQCBo/AACAQMRknYtvTYBab+AbE29ra3Pmak2BmVlZWZkz961MUesV1OoRM7PKykpn3traKmv27t0rjyk5OTnOXD03Zvq81doa38/zPW+qxvc3TUhIcObLly+XNUB343sfUHyrWd5//31n7lvRdOyxxzrzYcOGyZq33npLHkN8UO/BPr739Pz8fGfuez3v2bPHmasVYWZmKSkpzty3Rk59fvmuT9UP+D4L1Tq0Xbt2yZqOwDd+AAAAgaDxAwAACASNHwAAQCBo/AAAAAJB4wcAABCImEz1Dh8+XB5TN19uamqSNWpq1Df5E43k5GRnrqZ7zMxqamqcuW9yVk0/RfP7JCYmymO+51RRE1PquTEza2xsdOa+ialevXo5c/XcAPFm8ODBzvyZZ56RNUcffbQz/8///E9Z8/zzzzvzN998U9ZUV1fLY4h/vuldZc6cOc7ct+WjT58+ztw3oauOqYlaMz1ZnJ6eHvHj1NbWypqKigpn7psE7gh84wcAABAIGj8AAIBA0PgBAAAEgsYPAAAgEDR+AAAAgaDxAwAACESHzhCrmzx/8MEHsmb9+vXOvLm5WdaodS6+VSY9erh73paWFlmTmZnpzHv37i1r1PoTlZuZJSUlOXPfyLcaR1drUczMqqqqnHlOTo6sKSwsdOa+503dIF49vpleNfPRRx/JGqC7OeWUU+SxkSNHOvPjjz9e1qj3oocffljWbNy40Zmfe+65sqazbyqPL0d9Fpvp1SzRrGzxvZ7V+hPf54Ba5+JbAaM+p/Py8mRNVlaWM/etKVM9hG/VkTrvI444QtYsXrzYmfv+pofCN34AAACBoPEDAAAIBI0fAABAIGj8AAAAAkHjBwAAEIgOnepV06HvvPOOrDlw4IAzz87OljVq4ldN3ZjpaR3fpExra6sz37Jli6wpLS115r7fRz0HatrXTE8yqYlaM/28+aasVI1v4ljdHNs3Da0mtfv37y9rgK7qjDPOcOZqSt7MbPbs2c7cd30+8cQTztw3aThw4EBnrq5BM/9UZXei3u+jmWgNyeTJk5257/1ZbezwfQ6o7Q6DBg2SNeozT03umpmlpqY6c99mEPU45eXlskZd7wUFBbJG+TKvUb7xAwAACASNHwAAQCBo/AAAAAJB4wcAABAIGj8AAIBA0PgBAAAEokPXuWRkZDhztXrETK8dSElJkTX19fXO3LeOQI2W+27KXFlZ6czXrFkja0aMGOHM1aobMz1CrtbJmJk1NjY6c9/It/p5mzZtkjU1NTXOPD09Xdao0Xu15sVMr1nwrcFB1xTNzcS74zqNSZMmyWPqGjjzzDNlzcKFC535/fffL2vuueceZ75q1SpZs2/fPmcezftNd9NZr7NorgElmnP21aj37qOOOkrWDB061Jmrz0jf4/hWA6nnzbfSSK09871m1doY35oy9Rmem5sra/bu3evMx40bJ2v69u3rzNV1ezj4xg8AACAQNH4AAACBoPEDAAAIBI0fAABAIGj8AAAAAtGhU70lJSXO3DdhpiZyRo4cKWvUdIuaoDEza25uduY9euheWE20HnfccbJG3YDaN3Gsbhi9f/9+WaMmm9W0kpmervbdNFtNHPumetVklG/STP0d1N8A7cc3gaiOHThwQNZ0xwldH/UcjB07VtZMmzbNmf/617+WNX/961+due+G7mPGjHHmy5cvlzXqb+fbpOB7X+lOOmvivD2vAfUebKY/PwcPHixrfJ+tiprEzcvLkzV9+vRx5r7PXLXFwffaVM+Bys30NeA7t/Lycmeuegsz/bypDShm+r3jL3/5i6w5FL7xAwAACASNHwAAQCBo/AAAAAJB4wcAABAIGj8AAIBA0PgBAAAEokPXuRxzzDHO3LfORa2A8Y1iq3UhanzczCwrK8uZ19XVyZohQ4Y484EDB8qaaNYeqJuj+9asqBFy3w2w1U2r1ZoXM/2cqufTzKxXr17O3LeaRa27ac+bncPNt3oimrUUaiWCWtVgZlZRURHx40RDvZ58v+cpp5zizNXaBTOzJUuWOHO1ssXH9x518sknO/Pnn39e1uzZs8eZ+1Y0VVVVyWPdSWetGlIrunzv6ep90/e5pq6pfv36yRp1ffre09Xv41s1o97TfeemVpj51qyo50e9zs30ehjf61ytc8nJyZE10fQd6ppmnQsAAAAOicYPAAAgEDR+AAAAgaDxAwAACASNHwAAQCA6dKp32LBhzvy5556TNeom476bwKelpTlzNUVkpqdt1c8yM8vNzXXmvgkjxff7KGp62UxPJfl+HzXx6zs3NV3tm+ZSU8q+iTo1Neabfop3vteZei6jmVrMz8+Xx6ZPn+7MfZPtAwYMcOZDhw6VNeeff7481p7U8zNo0CBZM2PGDGfum1K/9957Izsxj3379slj6pqeNGmSrHnllVecuZoqNfPfiD4ejBw5Uh4rKipy5mpLgpl+P1Pv22bRbYRQE62+x1FTqL6a+vp6Z97S0iJr1PuXb3pcPde+90K1lcK3KUC9D/h6CHXee/fulTXqvPv27StronkdHArf+AEAAASCxg8AACAQNH4AAACBoPEDAAAIBI0fAABAIGj8AAAAAtGh61zUiPKGDRtkjVr94Vsxom60npycLGt8q1EUNfLtW22gHsc3jq5+12jWxvhG8tW6Bt9aAsW3zkXx/T7qb6fWCIQgmhVA0Tj99NPlMbUqQa0RMTN74oknnHlpaamsmTdvnjN/4IEHZE17Ov744+Ux9bp97LHHIn6caN4HfNS6I9/7gOJbZeFb29GdqPUnF154oaz55JNPnHlZWZmsUSs51HosM/03870u1N8sIyMj4hrf31idg281i3qcqqoqWaOuD9/vo2RlZcljaqWNb7XV1q1bnbmv74jmOvS9T0aLb/wAAAACQeMHAAAQCBo/AACAQND4AQAABILGDwAAIBAdOtWrJpnKy8tljZpK800/qckf3+Sumkry3dReTbv6JvPUOfgm5tSErJpe9olmMtD3vKnnx/ccqN81mqle398n3h111FHy2IcffujMo3m+nn76aXlMTbCr69ZMT7L5JtyKi4udubrZvVl00+gjRoxw5hMnTpQ16r3orbfeivjxO+v17Js0VNen7/2msybMO1pJSYkzP/LII2XNhAkTnLnvOdm7d29EebQ16jPX916rNmmoiWczs8GDBzvzoUOHyhr189SmADP9uvW9d6j3It/fR52b7/3m6KOPlseUPXv2OHPfBPXy5csjfpxD4Rs/AACAQND4AQAABILGDwAAIBA0fgAAAIGg8QMAAAgEjR8AAEAgOnSdS0VFhTPPy8uTNWpUPZqVKb51BNGsRlFrHHyrWaIZr1eP4xtHV8eiqfGJpkY919H8TaO5yXW8+O53vyuP5ebmOvMFCxbImvfee8+Zq3UVZmZFRUXOfMeOHbImmteMWqNw5ZVXyppf/OIXzjwtLU3WnHnmmc7ct2bl+eefl8cU32tdiWbVS21trTOvqqqSNdG8r0WzOqcrevfdd535XXfdJWsuvPBCZ96rVy9ZM2jQIGeu1smYmWVkZDjzaFazjBs3Ttaov6VvxYhSU1Mjj6nPwt27d8satf5E9RZm+v3Gt6KnrKzMmTc0NET8OOr3NNPPqe89auPGjfJYtPjGDwAAIBA0fgAAAIGg8QMAAAgEjR8AAEAgaPwAAAAC0aFTvY8++qgzLygokDXr1q1z5mrK00xPv/kmd9VklG8CUf28aKYWExMTI66JZkI3msdp7xvHq+fa9/dRE3LRTEfGiyeffFIe+4//+A9n7psaVBPSY8aMkTX79u1z5mqa0Cy619MHH3zgzI844ghZc9JJJzlz383U1UTrMcccI2v+/d//XR5T1PXZ3q9n9fPS09NljXpv9U0aRjPx2RWpyeV33nlH1viOKeq9bsCAAbJGTdD7atQ1XVdXJ2vUxLeadDXT2zf2798va9r7c0XJz8935ieeeKKseeutt5y577pJTk525llZWbJGTWrn5OTImmheb4cS7qcoAABAYGj8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASCxg8AACAQHbrOZfXq1c582rRpskaNqvvGxNUKA9+KCTVer8bhzfQ4uloJ4eNbZdKeolk146PO27eWQtX4Vs2oFRO+10G887021bqGaF6bS5YskcfUzeb79esna9Tfsry8XNaoa+3vf/+7rPnWt77lzF9//XVZM2rUKGf+4x//WNa0p/ZecRHNuojq6mpn7rs+O2s1R7xQz5dvZYrvGDT1vD3++OOdfCZdF9/4AQAABILGDwAAIBA0fgAAAIGg8QMAAAgEjR8AAEAgOnSqV1m8eLE89rvf/c6Z+6bI1M2SBw4cKGvUFGRjY6OsiWZCUt0E3DcFq35X35Sd4pvqVY/jmziOZhpZ/a6+36e0tNSZ19TURPz48cL3fKm/s+8m44rvb1xRUeHM6+vrZY26psaMGSNr1DXdu3dvWfO3v/1NHlPWrFnjzBctWiRr1Os5mgn69p6OVZsM1PNpZtbU1OTMfb9Pe28LANB5+MYPAAAgEDR+AAAAgaDxAwAACASNHwAAQCBo/AAAAAJB4wcAABCIDl3nolYINDc3y5rf/va3zvyOO+6QNR9++KEz37x5s6wpKChw5llZWbKmpaXFmftWG6jVGGrtgu+Yb/WDWhvT3nxraCKlnk8zs759+3b443c3vt99xIgRzlytLTIz279/vzPPyMiI+BwyMzMjrvH9PuoaWL9+vazZsGGDM7/66qtlzT333COPKe29gqU9qfdW3/uDeo+KZhUUgK4v3E9RAACAwND4AQAABILGDwAAIBA0fgAAAIGg8QMAAAhEh071RiM7O9uZ+yZA1fTwtm3bZE1ZWZkzz8/PlzV5eXnO3HdT++LiYmf+8ccfy5poJuYSExOdue/cfMfa6/HNzBobG5157969ZY26cbya4A7BM888I4/17Om+lL/61a/KmjFjxjjzjRs3yho16an+Xj579uyRx9RksbrWzczOPfdcZ75lyxZZU1pa6sx910Z7TrS29+OoqV7fpHZKSooz901dR/P3BtA18I0fAABAIGj8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASCxg8AACAQXW6dy4oVK5y5b51LTk6OM1erYcz0WojKykpZo9aPXH/99bLmkUceceYjR46UNdGscYhmNYtazeG7ObvS2toqj6m/nW91jlop4lsBErI///nPznzhwoWyZsaMGc582LBhsqZPnz7OXK3sMTOrr6935hdddJGsef311515WlqarBkwYIAz/973vidr4o16X9u3b5+sUe83SUlJsiY1NTWyEwPQZfCNHwAAQCBo/AAAAAJB4wcAABAIGj8AAIBA0PgBAAAEIuHgYY6QRjM1qmqimVo96qij5LFLL73UmU+fPl3W9OvXz5n7bgI/cOBAZ96/f39ZU11dLY8h9qJ5LXa0aK61zpKRkeHMhwwZImuKi4ud+YQJE2SNmgQvLy+XNS+88IIzLysrkzXxZuXKlc783XfflTWffPKJMz/11FNlzZVXXunMP/74Y1nDtQZ0jkNda3zjBwAAEAgaPwAAgEDQ+AEAAASCxg8AACAQNH4AAACBoPEDAAAIxGGvcwEAAED3xjd+AAAAgaDxAwAACASNHwAAQCBo/AAAAAJB4wcAABAIGj8AAIBA0PgBAAAEgsYPAAAgEDR+AAAAgaDxAwAACASNHwAAQCBo/AAAAAJB4wcAABAIGj8AAIBA0Ph1AZdeeqklJCTI/ystLY31KQJxoampyW688UYbOHCgpaWl2eTJk+2VV16J9WkBcWnVqlU2e/Zs69evn6Wnp9uoUaPsl7/8ZaxPK3gJBw8ePBjrkwjd0qVLbdOmTZ/LDh48aFdddZUVFxfbBx98EKMzA+LLhRdeaAsXLrTrrrvOhg0bZg899JCtWLHCFi1aZNOmTYv16QFx429/+5udeeaZNm7cOJs7d65lZmbapk2b7MCBA3bXXXfF+vSCRuPXRS1evNimT59u8+fPt5tvvjnWpwN0e8uXL7fJkyfbT3/6U7v++uvNzKyxsdFGjRplubm5tmTJkhifIRAfqqurbfjw4TZ16lRbuHCh9ejBf1zsSvhrdFGPPfaYJSQk2EUXXRTrUwHiwsKFCy0xMdGuuOKKz7LU1FSbN2+eLV261LZv3x7DswPix2OPPWa7d++2+fPnW48ePayurs4OHDgQ69PC/6Lx64JaWlpswYIFNnXqVCsuLo716QBx4d1337Xhw4dbVlbW5/JJkyaZmdnq1atjcFZA/Hn11VctKyvLSktLbcSIEZaZmWlZWVl29dVXW2NjY6xPL3g0fl3Qyy+/bJWVlXbxxRfH+lSAuFFWVmb5+flfyD/Ndu7c2dmnBMSlDRs2WGtrq33961+3WbNm2VNPPWWXX3653XfffXbZZZfF+vSC1zPWJ4AveuyxxywpKcnOP//8WJ8KEDcaGhosJSXlC3lqaupnxwF8ebW1tVZfX29XXXXVZ1O855xzjjU3N9tvf/tbu/XWW23YsGExPstw8Y1fF1NbW2vPPfeczZo1y7Kzs2N9OkDcSEtLs6ampi/kn/6np7S0tM4+JSAufXotXXjhhZ/LP/0360uXLu30c8L/ofHrYp599lmrr6/nP/MC7Sw/P9/Kysq+kH+aDRw4sLNPCYhLn15LeXl5n8tzc3PNzGzfvn2dfk74PzR+Xcyjjz5qmZmZNnv27FifChBXxo4da+vXr7fq6urP5W+//fZnxwF8eePHjzcz+8LNBz79d7T9+/fv9HPC/6Hx60IqKirs1VdftbPPPtvS09NjfTpAXJkzZ461tbXZ/fff/1nW1NRkDz74oE2ePNkKCwtjeHZA/Pj036c/8MADn8t///vfW8+ePe3EE0+MwVnhUwx3dCFPPvmktba28p95gQ4wefJkO++88+ymm26y8vJyKykpsT/+8Y+2ZcuWL3xAAYjeuHHj7PLLL7c//OEP1traaieccIK9/vrr9uc//9luuukm/llFjHHnji5kypQptnnzZtu5c6clJibG+nSAuNPY2Gg/+MEP7E9/+pPt27fPRo8ebbfddpvNmjUr1qcGxJWWlha744477MEHH7SdO3fa4MGD7V/+5V/suuuui/WpBY/GDwAAIBD8Gz8AAIBA0PgBAAAEgsYPAAAgEDR+AAAAgaDxAwAACASNHwAAQCBo/AAAAAJx2HfuSEhI6MjzAGKiK66xDOVay8rKkse+853vOPOJEyfKmnnz5jnzysrKyE7sEK655hpnPnToUFnz61//2plv2bJF1rS1tUV0Xl0d11r78N1T+rLLLnPmkydPljU/+clPnPm6detkzYYNG5z5gQMHZI263n2vi8GDBzvzT+8F7HLhhRc684qKCllz7733OvMlS5bImq7sUNca3/gBAAAEgsYPAAAgEDR+AAAAgaDxAwAACETCwcP8F7fd8R/BAofCPziPTFFRkTMfPny4rMnOznbm6enpsqa2ttaZX3vttbLmK1/5ijNvbGyUNUpmZqY8ps7tjjvukDWrV6925nl5ebJm9+7dEf0sM7OysjJ5LNa41r5o1qxZ8tidd97pzFNTU2XN3//+d2c+bdo0WVNYWOjMm5ubZU1aWpozT05OljXqvNX1ZKaHRXyDT3V1dc581apVskZdh/Pnz5c1O3fudOYrV66UNZ2F4Q4AAACYGY0fAABAMGj8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASCdS4IGismvqi4uFgemzJlijP33Qezqqoq4nNQqx98P0vdw3Tq1KmyJiUlxZl/8sknsubxxx+Xx5QBAwY4c9+qGbUyo6CgQNaoe/8uW7ZMn1wnCfla69WrlzP/6KOPZM0//vEPZ+5bs6JWmfjuoXv88cc78549e8qaHj3c3xn169dP1iQlJTnzTZs2yRp13omJibLmtddec+YNDQ2yZsSIEfKYUlJS4sx99xPvLKxzAQAAgJnR+AEAAASDxg8AACAQNH4AAACBoPEDAAAIBFO9CFrIk4bKV7/6VXlM3Zjc9zyq6UDfjdbVz/PdBL6+vt6Z19TUyBp1g3g1UWtm1qdPH2eenp4ua5SWlhZ5TL0OfBOaRUVFzvytt96SNfv27ZPH2lPI19oZZ5zhzOfOnStr1MR3//79Zc2aNWuceW5urqzJy8tz5r4JXTVVq6bXzcxycnKc+dq1a2WNmu7ftm2brFF/00WLFsmas846y5nv2bNH1mRkZDjzP/zhD7Lm2WeflcfaE1O9AAAAMDMaPwAAgGDQ+AEAAASCxg8AACAQNH4AAACBoPEDAAAIhL4LM4C4NnToUGfuu5m5WpXgWx+ganyrNNQKGLVKxXcOvjUrAwcOjOjxzczq6uqcuVq/4ft5TU1Nskati/DdoL6srMyZDxkyRNZ01jqXkE2bNs2Z+/6WlZWVzty3Bkm9nvfv3y9r1Ou5urpa1nz88cfO3LdqaMaMGc68oqJC1lRVVTnzgoICWXPrrbc68/fff1/WXHDBBc5c/Z5mZkcccYQzV7+nWeetczkUvvEDAAAIBI0fAABAIGj8AAAAAkHjBwAAEAgaPwAAgEAw1QsEKisry5m3trbKmpSUFGfum8xLS0tz5sOHD5c1vXv3duZJSUmypqSkxJn7plbVxO+WLVtkTU1NjTNvbm6WNWp6Uz2fZnp6s0cP/b/X1TH1N0DnWLNmjTP/1re+JWu++93vOvMxY8bImszMTGeen58va/r27evMfVP3auL3hRdekDWjRo2SxxT1HtWvXz9Zc9FFFznzjRs3yho12VxbWytrNmzY4My/9rWvyZqugm/8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASCxg8AACAQNH4AAACBYJ0LECi1SsS3YkStfti5c6esUSsZ1A3lzfR6GN/N5lNTU5257/dRN4HPycmRNQMGDHDmamWLmV4Bs2PHDlnT0NAQ8bkdOHBAHlP69OnjzNVzg8g9/vjjznzs2LGypqioyJkXFBTIml69ejnzp556StaMGDHCmc+YMUPW/OhHP3Lma9eulTVz58515r7VLOoaWLJkiawZP368Mx88eLCsUe83LS0tsmbFihXOfP78+bKmq+AbPwAAgEDQ+AEAAASCxg8AACAQNH4AAACBoPEDAAAIBFO9QBzzTbSqac7S0lJZM2zYMGc+c+ZMWbN48WJnftxxx8ma9957z5m3trbKGjU5q35PM7PGxkZn3rOnfmtUx3w3te/Rw/2/sZOSkmSNet7y8vJkTVtbW8SPk52d7cyZ6u14P/7xj+Wx3/zmN848LS1N1qxcudKZr1mzRtacfPLJzvydd96RNdu2bXPm//RP/yRr1NR9dXW1rFFT6o888oisGTNmjDO/8847ZU1hYaEz//73vy9rJkyYII91dXzjBwAAEAgaPwAAgEDQ+AEAAASCxg8AACAQNH4AAACBoPEDAAAIBOtcgDjmW0uiViX4qHUhl19+uax54IEHnHllZaWsKSkpcea+c05OTnbmffv2lTU7duxw5s3NzbKmV69eEf0sM7Phw4c78507d8oatYamoKBA1qxatcqZq3M2M8vMzJTH0D7Uqh/fypzVq1c780suuUTWbN261Zkfe+yxskat8/GtJ1LX9J49e2SNOuZb0TR48GBnrtavmJn993//tzP/0Y9+JGv27t3rzH3rsLozvvEDAAAIBI0fAABAIGj8AAAAAkHjBwAAEAgaPwAAgEAw1dvBfJNRysGDByOuUTdhHzRokKzZsmVLxI8Ta4mJifKYeq7VJGoITjvtNHlMTfP5bgKflZXlzNVEre9YQ0ODrDnuuOOc+dKlS2VNRUWFPKbk5OQ4c9+5qQnAfv36yZqhQ4c688bGRllz9tlnO/P8/HxZ89prrznzkSNHypqioiJn7pu2/OCDD+QxfFE07+l33XWXM/dNmh511FHOfPr06bJm2bJlznzhwoWyZuLEic78xRdflDW/+tWvIn6c3NxcZ+6bbP7tb3/rzN9//31ZM2bMGGc+d+5cWdOd8Y0fAABAIGj8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASCxg8AACAQrHOJQI8e7j7Zd+P49lzNcsYZZ8iaOXPmOPOBAwfKmlmzZjlz3w3q1coU3+/ZnittQl7NEo1o1t9MmDBB1vTv39+Z79+/X9ao19OOHTtkzebNm515S0uLrFHrVDZt2iRrUlNT5TFFvQbV+4OZvkF9WVmZrJkxY4YzP+mkk2TN9u3bnXmfPn1kjVpdo96H0H58743qPfDJJ5+UNbfffrszb2pqkjVqnYpv/YlaczJ79mxZo15PH3/8saxRa1tWrVola4YMGeLMfSunSktLnfm6detkTXfGN34AAACBoPEDAAAIBI0fAABAIGj8AAAAAkHjBwAAEAimeiPgm95Vjj32WGd+1VVXyRp1Q3U1sWdmtmvXLmfum+r82te+5syfeeYZWRPNlHI0NUpmZqY8pm4cvmjRonZ7/O5mwYIFsT4FKS8vTx5T07tqctfMbPDgwc48KytL1qhJXN9ke8+e7rfNXr16yZr8/Hxnrqakzcwef/xxZ7527VpZ88c//tGZ+6auETvRTPXm5ubKmpSUFGdeU1Mja26++WZn7vu8UZ9r6rPLzOz3v/+9M/d9RpWXlztzNfVvpq8137n5np9IRfM37Wx84wcAABAIGj8AAIBA0PgBAAAEgsYPAAAgEDR+AAAAgaDxAwAACESHrnPxjTVHWhPNKpVo+NaFnHvuuc58/PjxsmbMmDHO3HeD+hUrVjjz7OxsWTN69GhnXl9fL2tOPfVUZ7548WJZU1FRIY9FasKECfLYeeed58x79+4ta9SN6OP1RtuHoyusFlDX1J49e2RNenq6M29ra5M1H3zwgTP33Zzdd0xR15RaQWOmV0n4VnP8/e9/d+avvfaa5+zQnbT3NZiWlubMfStT1DVQVlYmax566CFnfvbZZ8uak08+2Zmr9StmZn379nXmvtUsp5xyijNfv369rFFrneJVWL8tAABAwGj8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASiQ6d6o5lY6qxJw6OOOsqZ33333bImKSnJme/atUvWqAld383mCwoKnLm6ObyZWWVlpTNXU1FmZtOnT3fmb7zxhqxRN4j3TV2r37W5uVnWqCk031SnOgff8xbvusJNwdVrUF0bZmbvv/++M9+wYUPEj9/U1CSP1dXVOXPfTdvVBKBvMjAnJ8eZ+16bgwYNcubqWkf3E83UfUNDg6xR74++qd7a2lpnXlRUJGv27t3rzNVnpJnZtm3bnLnvGlDPgW+qV30e33PPPbLmvvvuk8ci1RXecw+Fb/wAAAACQeMHAAAQCBo/AACAQND4AQAABILGDwAAIBA0fgAAAIGIyZ4L34oRtcLgmGOOkTVHHnmkM/fdAF09jlrvYGbW2NjozH03ej/66KOduW/sXa2SUI9vpm8Qv3//flmjbjbvWzUzYsQIZ+5bMaDWafieNzUSX1VVJWsGDx7szIuLi2UNOl5ra2tEuZle8ZCXlydr1PXue22qVRbDhg2TNerYjh07ZM26deucue85KC8vl8cAF99aLUV9rvg+p8844wxnrq4nM7OMjAxn3r9/f1mjPid917S6Dn1rYyoqKuSxeMQ3fgAAAIGg8QMAAAgEjR8AAEAgaPwAAAACQeMHAAAQiMOe6lU3k543b56smTRpkjPPzs6WNWrKzXeTaVXjm/zZt2+fM/fdNFvdANt3c3Y1leR7nN69eztz33Og+KYGU1NTnfnu3btljZra8k2TqWmq5uZmWaOmrNLT02WNmh5W02ToHOq68U3dq/cINSVvZrZ161Zn7puOzcnJcebnnXeerFFT9yUlJbJm8+bNznzPnj2yRj1vgKJeM77XUkpKijP3bZFQfO/paovDW2+9JWuGDBnizHv16iVr1DWl+hEzs7Fjx8pjkfJ9tqttFZ2Nb/wAAAACQeMHAAAQCBo/AACAQND4AQAABILGDwAAIBA0fgAAAIE47HUul1xyiTM/6aSTZI1ar1BXV6dPSKz+8K3xUGPivpsyqxF2tX7FTK8s8a0yqa6udua+1SxqPYzv3NRz4Ds3NXrvG5WP5ibg0fw+eXl5zty3LkCN0avnBp1D/c1817Ras+JbnaSu9z59+siaYcOGOfOlS5fKGnUNqNesmX6ffOqpp2SNWk+EsPk+PxXf58327dud+YABA2SNWmm0YcMGWTNo0CBn/sgjj8ian/zkJxE9vpnZyJEjnbnvc+3tt9+Wx+IR3/gBAAAEgsYPAAAgEDR+AAAAgaDxAwAACASNHwAAQCAOe6pX3TR9xIgRsmbo0KHOvLS0VNbs37/fmftufFxVVeXM09LSZE1qaqozb2lpkTXqHNTPMtOTi75za21tjSj3nZtvstl33u1JTUFGc0Nv3zmrm4q35w24ETn1us3KypI1ffv2deb19fWy5phjjnHmvulx9ZqJ5gb1vknDfv36OXN1E3ozvRUBYfNdN7W1tc58586dskZdU75JYPX+XFhYKGt69+7tzG+99VZZU15e7sx9nwPqeld9gplZ//79nblvI4Tv86ur4xs/AACAQND4AQAABILGDwAAIBA0fgAAAIGg8QMAAAgEjR8AAEAgDnudy89//nNnvmLFClnzz//8z8582rRpskatU1E3XvbxrX5QY+979+6VNercfCtg1CoT35oVtZrFt9JG3bzed1N7dcx3bmrEP5rfx7dmQ43R+1ZcqLUtod2Au6tRrzO1IsrMrK2tzZn7rgG1TiU3N9dzdm6+dRG+611R6zR8KyF81xTC5btuDh486MzV55CZXg/je/2px1G5mX6/37Vrl6y58847nfmNN94oa9RqlhdffFHWTJgwwZn36tVL1lRWVspjXR3f+AEAAASCxg8AACAQNH4AAACBoPEDAAAIBI0fAABAIL702Nhbb70V1TGloKDAmRcVFcmacePGOfNRo0ZF/Dh9+vSRNU1NTc5c3YTeTE9TqZ/l+3m+G8er6UDf1KCaTvT9PqrGNzWmJqirq6tlTUVFhTP33WhbTYetXr1a1vimw9A+1KRfenq6rFGvdd9rMzMz05n7rgE1PZyWliZr1OvWNwGo3r9KS0tljW9CEvEhmr+xes2a6UncwYMHy5p169Y587KyMlmjznvAgAGyRn3m9evXT9acc845zvyII46QNeqaKiwslDVqUtq3FUPpDtct3/gBAAAEgsYPAAAgEDR+AAAAgaDxAwAACASNHwAAQCBo/AAAAALR5e4CvmPHjohyM7MlS5Z01OkA+JLUmpVoVgDl5OTImt69eztztYLIzCwlJcWZqxvXm+mVGb61MYpvrVNqamrEPw9dU0JCgjOPZvXHrFmz5LGGhoaIH0ddA771ROra9a1BUufmW9V21llnOXPf77Ny5Upn7lsbo1bkDBkyRNaolWPqb23WdVa98I0fAABAIGj8AAAAAkHjBwAAEAgaPwAAgEDQ+AEAAASiy031AogvatLvwQcflDVqQtZ3g3rFNx2rpuxaW1tlTVJSkjNvbGyUNWqyWeVm/slidC/tOc2ZnZ0tj6lpW99106dPH2euptfN9PW5bt06WfP666878+uvv17WrF692pkPGDBA1kyZMsWZV1VVyRo1cTxmzBhZs3z5cnmsq+MbPwAAgEDQ+AEAAASCxg8AACAQNH4AAACBoPEDAAAIBI0fAABAIFjnAqBDqZUlaiWEmVliYmK7Pb7vZ6kbqvtutK74VrOo9TBqNQyg+NYGZWRkOHO1rsRMvzZ9K2jS09Od+bJly2TNVVdd5cxXrVola+69915n/m//9m+yRq1v8r3ftLS0OPMjjjhC1ijtubqno/CNHwAAQCBo/AAAAAJB4wcAABAIGj8AAIBA0PgBAAAEgqleAB1K3SBeTSD6anwTje0pOTlZHlM3r/dNDapJP/WzzMwOHDggj0Uqminl7jCd2F2o5z+a57i2tlYeU9eU7/WsXme+c8vOznbm48aNkzXqHMaMGSNrcnNznblvgl5N6Pqo95X8/PyIf1Z3wDd+AAAAgaDxAwAACASNHwAAQCBo/AAAAAJB4wcAABAIGj8AAIBAsM4FQEz41i6oNScpKSkR/7wePfT/vlU/z7dmRa3m8K1MiebG8aomGqxmia32XOfSr18/eay8vNyZP/zww7Lm2muvdeatra2yZu3atc789NNPlzVqDU1VVZWsGT9+vDP/6KOPZI1aKeN771DXe319vazpzvjGDwAAIBA0fgAAAIGg8QMAAAgEjR8AAEAgaPwAAAACwVQvgA7Vt29fZ+6bGlQaGhrksaSkJGfum5xsa2uL6GeZ6ZvNJyYmyhrF9xyo5w1h6N27tzNPS0uTNdu3b3fm6nXu47sGysrKnHldXZ2smTp1qjP/5JNPZM3EiROd+dFHHy1rtm7d6sx97wP79u1z5v3795c13Rnf+AEAAASCxg8AACAQNH4AAACBoPEDAAAIBI0fAABAIGj8AAAAAsE6FwAdKi8vz5m3tLRE/LN8NeqYb5WFWsHiu6F7jx7u/73sW+dy4MABZ+5bzVFdXS2PoXvxrRJR9u/f78yrqqpkTVFRkTO/5ZZbZI1aT/Thhx/KmjfffNOZz5w5U9b07OluN9S1YWaWm5vrzH3Xjbo+6+vrZc2IESOceWlpqazpzvjGDwAAIBA0fgAAAIGg8QMAAAgEjR8AAEAgaPwAAAACkXDwMMeNEhISOvpcgE4XzbRdR4u3a+3EE0905llZWbJG/V3S09Mjfvzm5mZ5TE0A+m5Qr/4+vseJZoK5pqbGmS9atCjin9UVcK11PHVNDRkyRNYMGzbMmb/88suyJiMjw5nfeOONskZN16tr0MysqanJmfuutfLycmdeWVkpa9avX+/MV61aJWu6skNda3zjBwAAEAgaPwAAgEDQ+AEAAASCxg8AACAQNH4AAACBoPEDAAAIxGGvcwEAAED3xjd+AAAAgaDxAwAACASNHwAAQCBo/AAAAAJB4wcAABAIGj8AAIBA0PgBAAAEgsYPAAAgEDR+AAAAgfh/pxfHoNYRfFoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This cell is designed to display a few images from the dataset\n",
    "#It isn't necessary to run this, but it can help give a better idea of the challanges your model will face\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "# Displaying figures from the dataset randomly\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "    img, label = train_dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "3JLJ0ZFCER5m"
   },
   "outputs": [],
   "source": [
    "#Here we define the model parameters -- the general structure as provided here will produce a fully connected network [28x28] --> 32 --> 16 --> 10\n",
    "class MLP(nn.Module): #MLP stands for \"Multi-Layer Perceptron\"\n",
    "    def __init__(self): #this initializes the structure of the network\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256) ## First fully connected linear layer, 28*28 input features and 256 outputs\n",
    "        self.fc2 = nn.Linear(256, 128) ## Second fully connected linear layer, 256 inputs and 128 outputs\n",
    "        self.fc3 = nn.Linear(128, 10) ## 10 output features because MNIST has 10 target classes\n",
    "\n",
    "    def forward(self, x): #this modifies the elements of the intial structure defined above\n",
    "        x = x.view(-1, 28 * 28) #the array is sent in as a vector\n",
    "        x = torch.sigmoid(self.fc1(x)) ## Applying sigmoid activation for the first layer\n",
    "        x = torch.tanh(self.fc2(x)) ## Applying tanh activation for the second layer\n",
    "        x = self.fc3(x) ## no modifications to the activation of the output layer\n",
    "        return x\n",
    "\n",
    "# Initializing the neural network\n",
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "2hFOEXCPEVTw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.8904350686073303\n",
      "Epoch 1, Batch 200, Loss: 0.5552436327934265\n",
      "Epoch 1, Batch 300, Loss: 0.4937435209751129\n",
      "Epoch 1, Batch 400, Loss: 0.488674179315567\n",
      "Epoch 1, Batch 500, Loss: 0.4486476792395115\n",
      "Epoch 1, Batch 600, Loss: 0.43819622799754143\n",
      "Epoch 1, Batch 700, Loss: 0.4436705894768238\n",
      "Epoch 1, Batch 800, Loss: 0.41725158974528315\n",
      "Epoch 1, Batch 900, Loss: 0.41850311785936356\n",
      "Epoch 2, Batch 100, Loss: 0.3858136209845543\n",
      "Epoch 2, Batch 200, Loss: 0.3939781682193279\n",
      "Epoch 2, Batch 300, Loss: 0.38820263102650643\n",
      "Epoch 2, Batch 400, Loss: 0.38984438717365266\n",
      "Epoch 2, Batch 500, Loss: 0.38577166199684143\n",
      "Epoch 2, Batch 600, Loss: 0.3576371784508228\n",
      "Epoch 2, Batch 700, Loss: 0.34489414617419245\n",
      "Epoch 2, Batch 800, Loss: 0.36689691483974457\n",
      "Epoch 2, Batch 900, Loss: 0.3629496595263481\n",
      "Epoch 3, Batch 100, Loss: 0.33151262789964675\n",
      "Epoch 3, Batch 200, Loss: 0.360899228900671\n",
      "Epoch 3, Batch 300, Loss: 0.33971808522939684\n",
      "Epoch 3, Batch 400, Loss: 0.34747024402022364\n",
      "Epoch 3, Batch 500, Loss: 0.3469053515791893\n",
      "Epoch 3, Batch 600, Loss: 0.3380253940820694\n",
      "Epoch 3, Batch 700, Loss: 0.3473885301500559\n",
      "Epoch 3, Batch 800, Loss: 0.33029178239405155\n",
      "Epoch 3, Batch 900, Loss: 0.34780578017234803\n",
      "Epoch 4, Batch 100, Loss: 0.3338006898760796\n",
      "Epoch 4, Batch 200, Loss: 0.3035690376162529\n",
      "Epoch 4, Batch 300, Loss: 0.32806106746196745\n",
      "Epoch 4, Batch 400, Loss: 0.3162780173122883\n",
      "Epoch 4, Batch 500, Loss: 0.3151619942486286\n",
      "Epoch 4, Batch 600, Loss: 0.3263470883667469\n",
      "Epoch 4, Batch 700, Loss: 0.32719863280653955\n",
      "Epoch 4, Batch 800, Loss: 0.30348284304142\n",
      "Epoch 4, Batch 900, Loss: 0.3299244572222233\n",
      "Epoch 5, Batch 100, Loss: 0.3088377048820257\n",
      "Epoch 5, Batch 200, Loss: 0.316403709128499\n",
      "Epoch 5, Batch 300, Loss: 0.29878819301724435\n",
      "Epoch 5, Batch 400, Loss: 0.30701160334050653\n",
      "Epoch 5, Batch 500, Loss: 0.3213288275152445\n",
      "Epoch 5, Batch 600, Loss: 0.3166789734363556\n",
      "Epoch 5, Batch 700, Loss: 0.31829910054802896\n",
      "Epoch 5, Batch 800, Loss: 0.32299512207508085\n",
      "Epoch 5, Batch 900, Loss: 0.2986996825039387\n",
      "Epoch 6, Batch 100, Loss: 0.2838846093416214\n",
      "Epoch 6, Batch 200, Loss: 0.29464274533092977\n",
      "Epoch 6, Batch 300, Loss: 0.29846483692526815\n",
      "Epoch 6, Batch 400, Loss: 0.3034676842391491\n",
      "Epoch 6, Batch 500, Loss: 0.3055309921503067\n",
      "Epoch 6, Batch 600, Loss: 0.30670459263026717\n",
      "Epoch 6, Batch 700, Loss: 0.28839053750038146\n",
      "Epoch 6, Batch 800, Loss: 0.2865668399631977\n",
      "Epoch 6, Batch 900, Loss: 0.28382505863904955\n",
      "Epoch 7, Batch 100, Loss: 0.3040927463769913\n",
      "Epoch 7, Batch 200, Loss: 0.27733916208148\n",
      "Epoch 7, Batch 300, Loss: 0.2842006349563599\n",
      "Epoch 7, Batch 400, Loss: 0.2956185683608055\n",
      "Epoch 7, Batch 500, Loss: 0.26791704177856446\n",
      "Epoch 7, Batch 600, Loss: 0.2731004936993122\n",
      "Epoch 7, Batch 700, Loss: 0.2840040444582701\n",
      "Epoch 7, Batch 800, Loss: 0.2886918543279171\n",
      "Epoch 7, Batch 900, Loss: 0.27607262052595616\n",
      "Epoch 8, Batch 100, Loss: 0.27404431082308295\n",
      "Epoch 8, Batch 200, Loss: 0.29174661479890346\n",
      "Epoch 8, Batch 300, Loss: 0.26958198837935926\n",
      "Epoch 8, Batch 400, Loss: 0.28661399565637113\n",
      "Epoch 8, Batch 500, Loss: 0.26354893621057274\n",
      "Epoch 8, Batch 600, Loss: 0.27346232332289216\n",
      "Epoch 8, Batch 700, Loss: 0.2722300924360752\n",
      "Epoch 8, Batch 800, Loss: 0.28052326701581476\n",
      "Epoch 8, Batch 900, Loss: 0.2681791713088751\n",
      "Epoch 9, Batch 100, Loss: 0.24497242949903011\n",
      "Epoch 9, Batch 200, Loss: 0.26323608711361884\n",
      "Epoch 9, Batch 300, Loss: 0.25937856070697307\n",
      "Epoch 9, Batch 400, Loss: 0.25726693250238897\n",
      "Epoch 9, Batch 500, Loss: 0.2731952755153179\n",
      "Epoch 9, Batch 600, Loss: 0.26602211728692055\n",
      "Epoch 9, Batch 700, Loss: 0.2734240755438805\n",
      "Epoch 9, Batch 800, Loss: 0.26889088392257693\n",
      "Epoch 9, Batch 900, Loss: 0.2620157649368048\n",
      "Epoch 10, Batch 100, Loss: 0.2668566791713238\n",
      "Epoch 10, Batch 200, Loss: 0.26752824559807775\n",
      "Epoch 10, Batch 300, Loss: 0.26305440232157706\n",
      "Epoch 10, Batch 400, Loss: 0.27068287529051305\n",
      "Epoch 10, Batch 500, Loss: 0.2560956822708249\n",
      "Epoch 10, Batch 600, Loss: 0.2558763288706541\n",
      "Epoch 10, Batch 700, Loss: 0.2561598625779152\n",
      "Epoch 10, Batch 800, Loss: 0.2508861007541418\n",
      "Epoch 10, Batch 900, Loss: 0.24125287048518657\n",
      "Epoch 11, Batch 100, Loss: 0.24981732308864593\n",
      "Epoch 11, Batch 200, Loss: 0.25764714010059836\n",
      "Epoch 11, Batch 300, Loss: 0.25055210046470167\n",
      "Epoch 11, Batch 400, Loss: 0.24594356670975684\n",
      "Epoch 11, Batch 500, Loss: 0.2329116839170456\n",
      "Epoch 11, Batch 600, Loss: 0.2550608567148447\n",
      "Epoch 11, Batch 700, Loss: 0.25771688744425775\n",
      "Epoch 11, Batch 800, Loss: 0.24922656401991844\n",
      "Epoch 11, Batch 900, Loss: 0.2639297576993704\n",
      "Epoch 12, Batch 100, Loss: 0.25637239798903466\n",
      "Epoch 12, Batch 200, Loss: 0.23307489030063153\n",
      "Epoch 12, Batch 300, Loss: 0.2475624393299222\n",
      "Epoch 12, Batch 400, Loss: 0.2353765519708395\n",
      "Epoch 12, Batch 500, Loss: 0.22103855326771737\n",
      "Epoch 12, Batch 600, Loss: 0.2611604245752096\n",
      "Epoch 12, Batch 700, Loss: 0.2353791470825672\n",
      "Epoch 12, Batch 800, Loss: 0.23315386720001696\n",
      "Epoch 12, Batch 900, Loss: 0.245338741093874\n",
      "Epoch 13, Batch 100, Loss: 0.24019487351179122\n",
      "Epoch 13, Batch 200, Loss: 0.2309591331705451\n",
      "Epoch 13, Batch 300, Loss: 0.2432644235342741\n",
      "Epoch 13, Batch 400, Loss: 0.2313664697855711\n",
      "Epoch 13, Batch 500, Loss: 0.22543114610016346\n",
      "Epoch 13, Batch 600, Loss: 0.23921281356364488\n",
      "Epoch 13, Batch 700, Loss: 0.245505845323205\n",
      "Epoch 13, Batch 800, Loss: 0.25575051762163636\n",
      "Epoch 13, Batch 900, Loss: 0.2680946342647076\n",
      "Epoch 14, Batch 100, Loss: 0.2223779135197401\n",
      "Epoch 14, Batch 200, Loss: 0.2255884462594986\n",
      "Epoch 14, Batch 300, Loss: 0.22413712151348592\n",
      "Epoch 14, Batch 400, Loss: 0.22018648501485585\n",
      "Epoch 14, Batch 500, Loss: 0.23617998918518424\n",
      "Epoch 14, Batch 600, Loss: 0.2442371777445078\n",
      "Epoch 14, Batch 700, Loss: 0.2353707589954138\n",
      "Epoch 14, Batch 800, Loss: 0.24247484058141708\n",
      "Epoch 14, Batch 900, Loss: 0.2481120801717043\n",
      "Epoch 15, Batch 100, Loss: 0.2476600104570389\n",
      "Epoch 15, Batch 200, Loss: 0.23018098752945662\n",
      "Epoch 15, Batch 300, Loss: 0.20190081879496574\n",
      "Epoch 15, Batch 400, Loss: 0.23360740378499031\n",
      "Epoch 15, Batch 500, Loss: 0.22493143655359746\n",
      "Epoch 15, Batch 600, Loss: 0.22467393383383752\n",
      "Epoch 15, Batch 700, Loss: 0.23489672154188157\n",
      "Epoch 15, Batch 800, Loss: 0.22663661688566208\n",
      "Epoch 15, Batch 900, Loss: 0.22106822416186334\n",
      "Epoch 16, Batch 100, Loss: 0.20753061063587666\n",
      "Epoch 16, Batch 200, Loss: 0.2118163925409317\n",
      "Epoch 16, Batch 300, Loss: 0.22460766453295947\n",
      "Epoch 16, Batch 400, Loss: 0.21251974686980246\n",
      "Epoch 16, Batch 500, Loss: 0.21809677094221114\n",
      "Epoch 16, Batch 600, Loss: 0.22305415958166122\n",
      "Epoch 16, Batch 700, Loss: 0.22543663822114468\n",
      "Epoch 16, Batch 800, Loss: 0.22023349501192568\n",
      "Epoch 16, Batch 900, Loss: 0.22183728724718094\n",
      "Epoch 17, Batch 100, Loss: 0.2003401853889227\n",
      "Epoch 17, Batch 200, Loss: 0.22240897662937642\n",
      "Epoch 17, Batch 300, Loss: 0.20527738630771636\n",
      "Epoch 17, Batch 400, Loss: 0.22933171279728412\n",
      "Epoch 17, Batch 500, Loss: 0.22936078608036042\n",
      "Epoch 17, Batch 600, Loss: 0.22304781585931777\n",
      "Epoch 17, Batch 700, Loss: 0.21555270723998546\n",
      "Epoch 17, Batch 800, Loss: 0.22307124853134155\n",
      "Epoch 17, Batch 900, Loss: 0.21338378943502903\n",
      "Epoch 18, Batch 100, Loss: 0.19738001618534326\n",
      "Epoch 18, Batch 200, Loss: 0.19050413206219674\n",
      "Epoch 18, Batch 300, Loss: 0.20683063574135305\n",
      "Epoch 18, Batch 400, Loss: 0.21161252841353417\n",
      "Epoch 18, Batch 500, Loss: 0.20722032234072685\n",
      "Epoch 18, Batch 600, Loss: 0.21230276588350536\n",
      "Epoch 18, Batch 700, Loss: 0.21118770003318788\n",
      "Epoch 18, Batch 800, Loss: 0.22068342909216881\n",
      "Epoch 18, Batch 900, Loss: 0.21051111549139023\n",
      "Epoch 19, Batch 100, Loss: 0.20123473297804595\n",
      "Epoch 19, Batch 200, Loss: 0.1975748872756958\n",
      "Epoch 19, Batch 300, Loss: 0.20457548789680005\n",
      "Epoch 19, Batch 400, Loss: 0.2049889688193798\n",
      "Epoch 19, Batch 500, Loss: 0.21631555914878844\n",
      "Epoch 19, Batch 600, Loss: 0.20877290613949298\n",
      "Epoch 19, Batch 700, Loss: 0.20453282244503498\n",
      "Epoch 19, Batch 800, Loss: 0.19931223660707473\n",
      "Epoch 19, Batch 900, Loss: 0.21511892154812812\n",
      "Epoch 20, Batch 100, Loss: 0.19474057603627443\n",
      "Epoch 20, Batch 200, Loss: 0.19522393733263016\n",
      "Epoch 20, Batch 300, Loss: 0.20522631730884314\n",
      "Epoch 20, Batch 400, Loss: 0.19911136653274297\n",
      "Epoch 20, Batch 500, Loss: 0.2170974040031433\n",
      "Epoch 20, Batch 600, Loss: 0.20094251424074172\n",
      "Epoch 20, Batch 700, Loss: 0.20421581022441387\n",
      "Epoch 20, Batch 800, Loss: 0.22642329581081866\n",
      "Epoch 20, Batch 900, Loss: 0.20422435898333788\n",
      "Epoch 21, Batch 100, Loss: 0.19315867561846972\n",
      "Epoch 21, Batch 200, Loss: 0.19566417001187802\n",
      "Epoch 21, Batch 300, Loss: 0.18650963265448808\n",
      "Epoch 21, Batch 400, Loss: 0.1855128340050578\n",
      "Epoch 21, Batch 500, Loss: 0.19778549000620843\n",
      "Epoch 21, Batch 600, Loss: 0.21550883680582048\n",
      "Epoch 21, Batch 700, Loss: 0.19567976836115122\n",
      "Epoch 21, Batch 800, Loss: 0.19413359865546226\n",
      "Epoch 21, Batch 900, Loss: 0.19962233237922192\n",
      "Epoch 22, Batch 100, Loss: 0.19494038049131632\n",
      "Epoch 22, Batch 200, Loss: 0.187799184396863\n",
      "Epoch 22, Batch 300, Loss: 0.18080638468265534\n",
      "Epoch 22, Batch 400, Loss: 0.18569236773997544\n",
      "Epoch 22, Batch 500, Loss: 0.19502530060708523\n",
      "Epoch 22, Batch 600, Loss: 0.2027067367732525\n",
      "Epoch 22, Batch 700, Loss: 0.21250334665179252\n",
      "Epoch 22, Batch 800, Loss: 0.20186619699001312\n",
      "Epoch 22, Batch 900, Loss: 0.19543917935341595\n",
      "Epoch 23, Batch 100, Loss: 0.17330639835447073\n",
      "Epoch 23, Batch 200, Loss: 0.1847006380558014\n",
      "Epoch 23, Batch 300, Loss: 0.19308319874107838\n",
      "Epoch 23, Batch 400, Loss: 0.19063947722315788\n",
      "Epoch 23, Batch 500, Loss: 0.17691735558211805\n",
      "Epoch 23, Batch 600, Loss: 0.18483161684125662\n",
      "Epoch 23, Batch 700, Loss: 0.1758821017295122\n",
      "Epoch 23, Batch 800, Loss: 0.1858031637594104\n",
      "Epoch 23, Batch 900, Loss: 0.1946047820523381\n",
      "Epoch 24, Batch 100, Loss: 0.1759954336285591\n",
      "Epoch 24, Batch 200, Loss: 0.19035142462700605\n",
      "Epoch 24, Batch 300, Loss: 0.16636886540800333\n",
      "Epoch 24, Batch 400, Loss: 0.17507570896297694\n",
      "Epoch 24, Batch 500, Loss: 0.18641989395022393\n",
      "Epoch 24, Batch 600, Loss: 0.19885489527136088\n",
      "Epoch 24, Batch 700, Loss: 0.18760939605534077\n",
      "Epoch 24, Batch 800, Loss: 0.19080747626721858\n",
      "Epoch 24, Batch 900, Loss: 0.1967124777659774\n",
      "Epoch 25, Batch 100, Loss: 0.1847157594934106\n",
      "Epoch 25, Batch 200, Loss: 0.18103204037994147\n",
      "Epoch 25, Batch 300, Loss: 0.20256442695856094\n",
      "Epoch 25, Batch 400, Loss: 0.17667026579380035\n",
      "Epoch 25, Batch 500, Loss: 0.1636608871817589\n",
      "Epoch 25, Batch 600, Loss: 0.17150074891746045\n",
      "Epoch 25, Batch 700, Loss: 0.1741941460967064\n",
      "Epoch 25, Batch 800, Loss: 0.1905792335420847\n",
      "Epoch 25, Batch 900, Loss: 0.18039471633732318\n",
      "Epoch 26, Batch 100, Loss: 0.17684235084801914\n",
      "Epoch 26, Batch 200, Loss: 0.1703461617603898\n",
      "Epoch 26, Batch 300, Loss: 0.17744662646204235\n",
      "Epoch 26, Batch 400, Loss: 0.18492318756878376\n",
      "Epoch 26, Batch 500, Loss: 0.16647447234019638\n",
      "Epoch 26, Batch 600, Loss: 0.159191361553967\n",
      "Epoch 26, Batch 700, Loss: 0.14677227154374123\n",
      "Epoch 26, Batch 800, Loss: 0.19064710792154074\n",
      "Epoch 26, Batch 900, Loss: 0.1846039339900017\n",
      "Epoch 27, Batch 100, Loss: 0.15933877147734166\n",
      "Epoch 27, Batch 200, Loss: 0.17729172974824906\n",
      "Epoch 27, Batch 300, Loss: 0.16495272498577834\n",
      "Epoch 27, Batch 400, Loss: 0.17635412260890007\n",
      "Epoch 27, Batch 500, Loss: 0.1726432129740715\n",
      "Epoch 27, Batch 600, Loss: 0.17523995127528905\n",
      "Epoch 27, Batch 700, Loss: 0.17756392199546098\n",
      "Epoch 27, Batch 800, Loss: 0.17153876211494207\n",
      "Epoch 27, Batch 900, Loss: 0.18290187563747168\n",
      "Epoch 28, Batch 100, Loss: 0.15939442940056325\n",
      "Epoch 28, Batch 200, Loss: 0.1660845692642033\n",
      "Epoch 28, Batch 300, Loss: 0.16253965482115745\n",
      "Epoch 28, Batch 400, Loss: 0.16154429748654364\n",
      "Epoch 28, Batch 500, Loss: 0.17210747826844452\n",
      "Epoch 28, Batch 600, Loss: 0.1739950677007437\n",
      "Epoch 28, Batch 700, Loss: 0.1820777290686965\n",
      "Epoch 28, Batch 800, Loss: 0.15966541089117528\n",
      "Epoch 28, Batch 900, Loss: 0.1844446986168623\n",
      "Epoch 29, Batch 100, Loss: 0.15614937976002694\n",
      "Epoch 29, Batch 200, Loss: 0.17130941163748503\n",
      "Epoch 29, Batch 300, Loss: 0.17037649407982827\n",
      "Epoch 29, Batch 400, Loss: 0.1589592208713293\n",
      "Epoch 29, Batch 500, Loss: 0.1616502839140594\n",
      "Epoch 29, Batch 600, Loss: 0.16365733403712512\n",
      "Epoch 29, Batch 700, Loss: 0.16517659071832896\n",
      "Epoch 29, Batch 800, Loss: 0.17339450219646096\n",
      "Epoch 29, Batch 900, Loss: 0.16523757334798575\n",
      "Epoch 30, Batch 100, Loss: 0.15316700097173452\n",
      "Epoch 30, Batch 200, Loss: 0.1663806464523077\n",
      "Epoch 30, Batch 300, Loss: 0.16028621595352888\n",
      "Epoch 30, Batch 400, Loss: 0.17359258517622947\n",
      "Epoch 30, Batch 500, Loss: 0.16048172879964112\n",
      "Epoch 30, Batch 600, Loss: 0.15591843981295825\n",
      "Epoch 30, Batch 700, Loss: 0.16302237890660762\n",
      "Epoch 30, Batch 800, Loss: 0.1807390109077096\n",
      "Epoch 30, Batch 900, Loss: 0.16210172034800052\n",
      "Epoch 31, Batch 100, Loss: 0.1353524509072304\n",
      "Epoch 31, Batch 200, Loss: 0.15810118602588774\n",
      "Epoch 31, Batch 300, Loss: 0.14995840489864348\n",
      "Epoch 31, Batch 400, Loss: 0.17112264063209295\n",
      "Epoch 31, Batch 500, Loss: 0.1692674581333995\n",
      "Epoch 31, Batch 600, Loss: 0.14963160648941995\n",
      "Epoch 31, Batch 700, Loss: 0.16547657795250414\n",
      "Epoch 31, Batch 800, Loss: 0.17682942256331444\n",
      "Epoch 31, Batch 900, Loss: 0.16789871275424958\n",
      "Epoch 32, Batch 100, Loss: 0.1565292814001441\n",
      "Epoch 32, Batch 200, Loss: 0.15910101734101773\n",
      "Epoch 32, Batch 300, Loss: 0.1459041500836611\n",
      "Epoch 32, Batch 400, Loss: 0.16139486245810986\n",
      "Epoch 32, Batch 500, Loss: 0.15929922558367252\n",
      "Epoch 32, Batch 600, Loss: 0.1772362059354782\n",
      "Epoch 32, Batch 700, Loss: 0.15923712346702815\n",
      "Epoch 32, Batch 800, Loss: 0.15200765404850244\n",
      "Epoch 32, Batch 900, Loss: 0.16199873793870212\n",
      "Epoch 33, Batch 100, Loss: 0.13858708560466768\n",
      "Epoch 33, Batch 200, Loss: 0.15904803436249496\n",
      "Epoch 33, Batch 300, Loss: 0.15052074916660785\n",
      "Epoch 33, Batch 400, Loss: 0.15471002358943223\n",
      "Epoch 33, Batch 500, Loss: 0.15024329092353583\n",
      "Epoch 33, Batch 600, Loss: 0.1582394302263856\n",
      "Epoch 33, Batch 700, Loss: 0.16158339336514474\n",
      "Epoch 33, Batch 800, Loss: 0.14987101443111897\n",
      "Epoch 33, Batch 900, Loss: 0.14602124489843846\n",
      "Epoch 34, Batch 100, Loss: 0.1429603335261345\n",
      "Epoch 34, Batch 200, Loss: 0.15274651654064655\n",
      "Epoch 34, Batch 300, Loss: 0.1441976863052696\n",
      "Epoch 34, Batch 400, Loss: 0.13694291267544031\n",
      "Epoch 34, Batch 500, Loss: 0.14599208522588014\n",
      "Epoch 34, Batch 600, Loss: 0.15667837627232076\n",
      "Epoch 34, Batch 700, Loss: 0.14808888684958219\n",
      "Epoch 34, Batch 800, Loss: 0.15131971951574086\n",
      "Epoch 34, Batch 900, Loss: 0.1563226553797722\n",
      "Epoch 35, Batch 100, Loss: 0.14519681129604578\n",
      "Epoch 35, Batch 200, Loss: 0.13602611523121597\n",
      "Epoch 35, Batch 300, Loss: 0.13119331873953344\n",
      "Epoch 35, Batch 400, Loss: 0.13809591813012959\n",
      "Epoch 35, Batch 500, Loss: 0.1344249798730016\n",
      "Epoch 35, Batch 600, Loss: 0.16203026900067927\n",
      "Epoch 35, Batch 700, Loss: 0.1368439044058323\n",
      "Epoch 35, Batch 800, Loss: 0.14774396596476436\n",
      "Epoch 35, Batch 900, Loss: 0.16230983613058925\n",
      "Finished Training\n",
      "Training finished in 220.15907764434814 seconds\n"
     ]
    }
   ],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002) \n",
    "\n",
    "# Training the neural network\n",
    "num_epochs = 35\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "print('Finished Training')\n",
    "print(f'Training finished in {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "RNMCpk60EaXr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8836%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on test set: { correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "J2GkmLeQEeZV"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 27\n",
    "test_image, test_label = test_dataset[image_index]\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    output = model(test_image.unsqueeze(0))\n",
    "    _, predicted_label = torch.max(output, 1)\n",
    "\n",
    "test_image_numpy = test_image.squeeze().numpy()\n",
    "\n",
    "plt.imshow(test_image_numpy, cmap='gray')\n",
    "plt.title(f'Predicted Label: {predicted_label.item()}, Actual Label: {test_label}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoypxOXgGjuC"
   },
   "source": [
    "Notes for Part 1\n",
    "\n",
    "1. Activation fucntion:\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(28*28, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.relu(self.fc1(x))  # Change activation function here\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "2. loss function and optimizer\n",
    "\n",
    "model = Net()\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Change loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "3. ~adding a dropout layer\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(28*28, 128)\n",
    "        self.dropout = torch.nn.Dropout(0.2)  # Add a Dropout layer here\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Apply Dropout\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "4. model configurations / epochs\n",
    "\n",
    "epochs = 10  # Change number of epochs\n",
    "for epoch in range(epochs):\n",
    "    # Training loop\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Training steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5nxrEoAHAUX"
   },
   "source": [
    "## CNN Implimentation with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "ccRJi8VXH3_O"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "k41uN-aAIH6Y"
   },
   "outputs": [],
   "source": [
    "# Mapping the labels for the MNIST dataset\n",
    "labels_map = {\n",
    "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n",
    "    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "4_MUVyZ5Iksr"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "AEoqWEFz5Ms-"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "eX_tkHuwEK7B"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "7l92S_RxJZTm"
   },
   "outputs": [],
   "source": [
    "def create_model(num_layers=2, units_per_layer=128, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28)))\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        model.add(Dense(units_per_layer, activation=activation))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "nPfHtKytJd9Q"
   },
   "outputs": [],
   "source": [
    "num_layers = 6\n",
    "units_per_layer = 256\n",
    "activation = 'relu'\n",
    "learning_rate = 0.01\n",
    "epochs = 75\n",
    "batch_size = 48\n",
    "\n",
    "# Create the model\n",
    "model = create_model(num_layers=num_layers, units_per_layer=units_per_layer, activation=activation)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=SGD(learning_rate=learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "JlPkc9auJkET"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5552 - loss: 1.3828\n",
      "Epoch 2/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8097 - loss: 0.5368\n",
      "Epoch 3/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8354 - loss: 0.4623\n",
      "Epoch 4/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8464 - loss: 0.4220\n",
      "Epoch 5/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8593 - loss: 0.3893\n",
      "Epoch 6/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8663 - loss: 0.3688\n",
      "Epoch 7/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8722 - loss: 0.3443\n",
      "Epoch 8/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8799 - loss: 0.3287\n",
      "Epoch 9/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8817 - loss: 0.3209\n",
      "Epoch 10/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8862 - loss: 0.3080\n",
      "Epoch 11/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8925 - loss: 0.2957\n",
      "Epoch 12/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8921 - loss: 0.2936\n",
      "Epoch 13/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8972 - loss: 0.2777\n",
      "Epoch 14/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8992 - loss: 0.2747\n",
      "Epoch 15/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8988 - loss: 0.2663\n",
      "Epoch 16/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9068 - loss: 0.2568\n",
      "Epoch 17/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9088 - loss: 0.2497\n",
      "Epoch 18/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.2423\n",
      "Epoch 19/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.2394\n",
      "Epoch 20/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2327\n",
      "Epoch 21/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9162 - loss: 0.2248\n",
      "Epoch 22/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9171 - loss: 0.2202\n",
      "Epoch 23/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9188 - loss: 0.2153\n",
      "Epoch 24/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9216 - loss: 0.2095\n",
      "Epoch 25/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9238 - loss: 0.2065\n",
      "Epoch 26/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9251 - loss: 0.2015\n",
      "Epoch 27/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.1952\n",
      "Epoch 28/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.1960\n",
      "Epoch 29/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9323 - loss: 0.1841\n",
      "Epoch 30/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9314 - loss: 0.1878\n",
      "Epoch 31/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9326 - loss: 0.1790\n",
      "Epoch 32/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.1768\n",
      "Epoch 33/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9354 - loss: 0.1720\n",
      "Epoch 34/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9380 - loss: 0.1655\n",
      "Epoch 35/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9394 - loss: 0.1633\n",
      "Epoch 36/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.1575\n",
      "Epoch 37/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.1511\n",
      "Epoch 38/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.1474\n",
      "Epoch 39/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1449\n",
      "Epoch 40/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1386\n",
      "Epoch 41/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1369\n",
      "Epoch 42/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1370\n",
      "Epoch 43/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9514 - loss: 0.1314\n",
      "Epoch 44/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9537 - loss: 0.1259\n",
      "Epoch 45/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9543 - loss: 0.1261\n",
      "Epoch 46/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9555 - loss: 0.1196\n",
      "Epoch 47/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9568 - loss: 0.1182\n",
      "Epoch 48/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9571 - loss: 0.1137\n",
      "Epoch 49/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9584 - loss: 0.1113\n",
      "Epoch 50/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.1115\n",
      "Epoch 51/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9613 - loss: 0.1052\n",
      "Epoch 52/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9628 - loss: 0.1030\n",
      "Epoch 53/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9626 - loss: 0.1021\n",
      "Epoch 54/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9643 - loss: 0.0981\n",
      "Epoch 55/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9642 - loss: 0.0964\n",
      "Epoch 56/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9674 - loss: 0.0904\n",
      "Epoch 57/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9681 - loss: 0.0879\n",
      "Epoch 58/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9703 - loss: 0.0845\n",
      "Epoch 59/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9677 - loss: 0.0877\n",
      "Epoch 60/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9706 - loss: 0.0813\n",
      "Epoch 61/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9694 - loss: 0.0824\n",
      "Epoch 62/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9726 - loss: 0.0767\n",
      "Epoch 63/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9716 - loss: 0.0766\n",
      "Epoch 64/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9725 - loss: 0.0747\n",
      "Epoch 65/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9722 - loss: 0.0738\n",
      "Epoch 66/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9746 - loss: 0.0699\n",
      "Epoch 67/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9748 - loss: 0.0693\n",
      "Epoch 68/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9757 - loss: 0.0664\n",
      "Epoch 69/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9756 - loss: 0.0686\n",
      "Epoch 70/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9772 - loss: 0.0635\n",
      "Epoch 71/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9778 - loss: 0.0603\n",
      "Epoch 72/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.0615\n",
      "Epoch 73/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.0599\n",
      "Epoch 74/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9786 - loss: 0.0574\n",
      "Epoch 75/75\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9804 - loss: 0.0556\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.8916 - loss: 0.5115\n",
      "Test accuracy: 0.8888999819755554\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "ig5GXhcG5fy6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0509 - val_accuracy: 0.9729 - val_loss: 0.0679\n",
      "Epoch 2/75\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0475 - val_accuracy: 0.9738 - val_loss: 0.0669\n",
      "Epoch 3/75\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0488 - val_accuracy: 0.9782 - val_loss: 0.0612\n",
      "Epoch 4/75\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0442 - val_accuracy: 0.9562 - val_loss: 0.1148\n",
      "Epoch 5/75\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0436 - val_accuracy: 0.9665 - val_loss: 0.0889\n",
      "Epoch 6/75\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0473 - val_accuracy: 0.9742 - val_loss: 0.0702\n",
      "Epoch 7/75\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0393 - val_accuracy: 0.9691 - val_loss: 0.0821\n",
      "Epoch 8/75\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0399 - val_accuracy: 0.9681 - val_loss: 0.0849\n",
      "Epoch 9/75\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9860 - loss: 0.0400 - val_accuracy: 0.9603 - val_loss: 0.1047\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.8911 - loss: 0.5187\n",
      "Test accuracy: 0.8919000029563904\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "zJa4Lf76KZDM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 27\n",
    "\n",
    "# Extract the test image and label\n",
    "test_image = x_test[image_index]\n",
    "test_label = np.argmax(y_test[image_index])\n",
    "\n",
    "# Reshape the test image for prediction (Keras expects a batch dimension)\n",
    "test_image_reshaped = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "# Make predictions on the test image\n",
    "predicted_label = np.argmax(model.predict(test_image_reshaped), axis=-1)\n",
    "\n",
    "# Plot the test image with predicted and actual labels\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "plt.title(f'Predicted Label: {predicted_label[0]}, Actual Label: {test_label}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "cc8F7Lo_AOII"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.7453 - loss: 0.7697\n",
      "Epoch 2/13\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.8561 - loss: 0.4187\n",
      "Epoch 3/13\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.8747 - loss: 0.3698\n",
      "Epoch 4/13\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.8870 - loss: 0.3414\n",
      "Epoch 5/13\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8930 - loss: 0.3285\n",
      "Epoch 6/13\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8965 - loss: 0.3130\n",
      "Epoch 7/13\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9000 - loss: 0.3086\n",
      "Epoch 8/13\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9060 - loss: 0.2834\n",
      "Epoch 9/13\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9065 - loss: 0.2891\n",
      "Epoch 10/13\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9104 - loss: 0.2706\n",
      "Epoch 11/13\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9123 - loss: 0.2730\n",
      "Epoch 12/13\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.2557\n",
      "Epoch 13/13\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9156 - loss: 0.2639\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9097 - loss: 0.3254\n",
      "\n",
      "Test accuracy: 0.9096999764442444\n",
      "Training finished in 221.6615481376648 seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(64, (5, 5), input_shape=(28, 28, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0003),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images.reshape(-1, 28, 28, 1), train_labels, batch_size=16, epochs=13)\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images.reshape(-1, 28, 28, 1), test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print(f'Training finished in {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
       "\n",
       " conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> \n",
       "\n",
       " batch_normalization_55                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
       "\n",
       " activation_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " max_pooling2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \n",
       "\n",
       " batch_normalization_56                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
       "\n",
       " activation_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " max_pooling2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " flatten_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> \n",
       "\n",
       " batch_normalization_57                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                              <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
       "\n",
       " activation_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \n",
       "\n",
       " batch_normalization_58                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
       "\n",
       " activation_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m1,664\u001b[0m \n",
       "\n",
       " batch_normalization_55                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)                       \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
       "\n",
       " activation_52 (\u001b[38;5;33mActivation\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " max_pooling2d_32 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    \u001b[38;5;34m36,928\u001b[0m \n",
       "\n",
       " batch_normalization_56                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)                       \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
       "\n",
       " activation_53 (\u001b[38;5;33mActivation\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " max_pooling2d_33 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)                           \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " flatten_20 (\u001b[38;5;33mFlatten\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)                               \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_70 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m204,928\u001b[0m \n",
       "\n",
       " batch_normalization_57                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                              \u001b[38;5;34m512\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
       "\n",
       " activation_54 (\u001b[38;5;33mActivation\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_29 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_71 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                             \u001b[38;5;34m8,256\u001b[0m \n",
       "\n",
       " batch_normalization_58                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                               \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
       "\n",
       " activation_55 (\u001b[38;5;33mActivation\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_30 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_72 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                               \u001b[38;5;34m650\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">506,774</span> (1.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m506,774\u001b[0m (1.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">253,066</span> (988.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m253,066\u001b[0m (988.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">253,068</span> (988.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m253,068\u001b[0m (988.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv2d_32\n",
      "Weights shape: (5, 5, 1, 64)\n",
      "Biases shape: (64,)\n",
      "\n",
      "Layer: batch_normalization_55\n",
      "Weights shape: (64,)\n",
      "Biases shape: (64,)\n",
      "\n",
      "Layer: conv2d_33\n",
      "Weights shape: (3, 3, 64, 64)\n",
      "Biases shape: (64,)\n",
      "\n",
      "Layer: batch_normalization_56\n",
      "Weights shape: (64,)\n",
      "Biases shape: (64,)\n",
      "\n",
      "Layer: dense_70\n",
      "Weights shape: (1600, 128)\n",
      "Biases shape: (128,)\n",
      "\n",
      "Layer: batch_normalization_57\n",
      "Weights shape: (128,)\n",
      "Biases shape: (128,)\n",
      "\n",
      "Layer: dense_71\n",
      "Weights shape: (128, 64)\n",
      "Biases shape: (64,)\n",
      "\n",
      "Layer: batch_normalization_58\n",
      "Weights shape: (64,)\n",
      "Biases shape: (64,)\n",
      "\n",
      "Layer: dense_72\n",
      "Weights shape: (64, 10)\n",
      "Biases shape: (10,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if weights:\n",
    "        print(f\"Layer: {layer.name}\")\n",
    "        print(f\"Weights shape: {weights[0].shape}\")\n",
    "        print(f\"Biases shape: {weights[1].shape}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nK1xXT5W7cMS"
   },
   "source": [
    "## AUTOMATED TUNING (EXETENDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "yIeVei_C8sVB"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1321126897.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[71], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "dl_proj2",
   "language": "python",
   "name": "dl_proj2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
