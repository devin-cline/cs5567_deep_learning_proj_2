{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hASLpyncBmvt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U portalocker>=2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3IIK5kzHGH0"
   },
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_aWMlQ33ByRO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jOCzfnBvB_bQ"
   },
   "outputs": [],
   "source": [
    "# Transformations --> this is a \"pre-processing step\" that's typical for image processing methods\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL image or numpy.ndarray to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize data to range [-1, 1]\n",
    "])\n",
    "# This dataset is already \"sorted\" as part of the import method, but no \"validation\" set has been selected in this case\n",
    "# Loading the FashionMNIST dataset\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Training and Testing loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jZk_FS9JCLOH"
   },
   "outputs": [],
   "source": [
    "# Mapping the labels for the MNIST dataset -- later we'll see that this using the \"keras to_categorical\" method as discussed in class\n",
    "labels_map = {\n",
    "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n",
    "    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ykrRIGSdCMu5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This cell is designed to display a few images from the dataset\n",
    "#It isn't necessary to run this, but it can help give a better idea of the challanges your model will face\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "# Displaying figures from the dataset randomly\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "    img, label = train_dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "3JLJ0ZFCER5m"
   },
   "outputs": [],
   "source": [
    "#Here we define the model parameters -- the general structure as provided here will produce a fully connected network [28x28] --> 32 --> 16 --> 10\n",
    "class MLP(nn.Module): #MLP stands for \"Multi-Layer Perceptron\"\n",
    "    def __init__(self): #this initializes the structure of the network\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256) ## First fully connected linear layer, 28*28 input features and 256 outputs\n",
    "        self.fc2 = nn.Linear(256, 128) ## Second fully connected linear layer, 256 inputs and 128 outputs\n",
    "        self.fc3 = nn.Linear(128, 10) ## 10 output features because MNIST has 10 target classes\n",
    "\n",
    "    def forward(self, x): #this modifies the elements of the intial structure defined above\n",
    "        x = x.view(-1, 28 * 28) #the array is sent in as a vector\n",
    "        x = torch.sigmoid(self.fc1(x)) ## Applying sigmoid activation for the first layer\n",
    "        x = torch.tanh(self.fc2(x)) ## Applying tanh activation for the second layer\n",
    "        x = self.fc3(x) ## no modifications to the activation of the output layer\n",
    "        return x\n",
    "\n",
    "# Initializing the neural network\n",
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "2hFOEXCPEVTw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.32632037028670313\n",
      "Epoch 1, Batch 200, Loss: 0.3189910535514355\n",
      "Epoch 1, Batch 300, Loss: 0.3229694002866745\n",
      "Epoch 1, Batch 400, Loss: 0.3384581986069679\n",
      "Epoch 1, Batch 500, Loss: 0.32703575626015663\n",
      "Epoch 1, Batch 600, Loss: 0.3107647831737995\n",
      "Epoch 1, Batch 700, Loss: 0.3411184245347977\n",
      "Epoch 1, Batch 800, Loss: 0.3161122757196426\n",
      "Epoch 1, Batch 900, Loss: 0.33349295794963835\n",
      "Epoch 2, Batch 100, Loss: 0.33110347971320153\n",
      "Epoch 2, Batch 200, Loss: 0.3317750607430935\n",
      "Epoch 2, Batch 300, Loss: 0.3286610400676727\n",
      "Epoch 2, Batch 400, Loss: 0.30529661402106284\n",
      "Epoch 2, Batch 500, Loss: 0.3091862464696169\n",
      "Epoch 2, Batch 600, Loss: 0.32464670404791834\n",
      "Epoch 2, Batch 700, Loss: 0.31791820138692856\n",
      "Epoch 2, Batch 800, Loss: 0.3155043666064739\n",
      "Epoch 2, Batch 900, Loss: 0.3397001102566719\n",
      "Epoch 3, Batch 100, Loss: 0.33076613768935204\n",
      "Epoch 3, Batch 200, Loss: 0.3203452344238758\n",
      "Epoch 3, Batch 300, Loss: 0.333949703425169\n",
      "Epoch 3, Batch 400, Loss: 0.32279512487351897\n",
      "Epoch 3, Batch 500, Loss: 0.3188712777197361\n",
      "Epoch 3, Batch 600, Loss: 0.31622588112950323\n",
      "Epoch 3, Batch 700, Loss: 0.3267413504421711\n",
      "Epoch 3, Batch 800, Loss: 0.31569472163915635\n",
      "Epoch 3, Batch 900, Loss: 0.3188528376817703\n",
      "Epoch 4, Batch 100, Loss: 0.3098280331492424\n",
      "Epoch 4, Batch 200, Loss: 0.32795069113373754\n",
      "Epoch 4, Batch 300, Loss: 0.31796928398311136\n",
      "Epoch 4, Batch 400, Loss: 0.312239995598793\n",
      "Epoch 4, Batch 500, Loss: 0.31801056206226347\n",
      "Epoch 4, Batch 600, Loss: 0.32049515306949616\n",
      "Epoch 4, Batch 700, Loss: 0.32617724657058716\n",
      "Epoch 4, Batch 800, Loss: 0.32981206819415093\n",
      "Epoch 4, Batch 900, Loss: 0.32262865915894506\n",
      "Epoch 5, Batch 100, Loss: 0.3138847628235817\n",
      "Epoch 5, Batch 200, Loss: 0.312795036137104\n",
      "Epoch 5, Batch 300, Loss: 0.3123274452984333\n",
      "Epoch 5, Batch 400, Loss: 0.31763537749648096\n",
      "Epoch 5, Batch 500, Loss: 0.33084524869918824\n",
      "Epoch 5, Batch 600, Loss: 0.3110328301787376\n",
      "Epoch 5, Batch 700, Loss: 0.3222062599658966\n",
      "Epoch 5, Batch 800, Loss: 0.32308211252093316\n",
      "Epoch 5, Batch 900, Loss: 0.32584530115127563\n",
      "Epoch 6, Batch 100, Loss: 0.318026525080204\n",
      "Epoch 6, Batch 200, Loss: 0.33422012254595757\n",
      "Epoch 6, Batch 300, Loss: 0.32867459923028947\n",
      "Epoch 6, Batch 400, Loss: 0.31236945249140263\n",
      "Epoch 6, Batch 500, Loss: 0.30343572318553924\n",
      "Epoch 6, Batch 600, Loss: 0.31634120777249336\n",
      "Epoch 6, Batch 700, Loss: 0.3319466224312782\n",
      "Epoch 6, Batch 800, Loss: 0.3021635030955076\n",
      "Epoch 6, Batch 900, Loss: 0.3187910921871662\n",
      "Epoch 7, Batch 100, Loss: 0.3383097603917122\n",
      "Epoch 7, Batch 200, Loss: 0.2998063638806343\n",
      "Epoch 7, Batch 300, Loss: 0.3142370933294296\n",
      "Epoch 7, Batch 400, Loss: 0.2969005002081394\n",
      "Epoch 7, Batch 500, Loss: 0.31204930812120435\n",
      "Epoch 7, Batch 600, Loss: 0.32736428871750833\n",
      "Epoch 7, Batch 700, Loss: 0.3153121295571327\n",
      "Epoch 7, Batch 800, Loss: 0.30954939931631087\n",
      "Epoch 7, Batch 900, Loss: 0.3198825354874134\n",
      "Epoch 8, Batch 100, Loss: 0.3078937615454197\n",
      "Epoch 8, Batch 200, Loss: 0.3206641486287117\n",
      "Epoch 8, Batch 300, Loss: 0.31855607107281686\n",
      "Epoch 8, Batch 400, Loss: 0.31326475471258164\n",
      "Epoch 8, Batch 500, Loss: 0.3225835235416889\n",
      "Epoch 8, Batch 600, Loss: 0.29957033962011337\n",
      "Epoch 8, Batch 700, Loss: 0.3203120431303978\n",
      "Epoch 8, Batch 800, Loss: 0.3113772803544998\n",
      "Epoch 8, Batch 900, Loss: 0.30751007556915283\n",
      "Epoch 9, Batch 100, Loss: 0.3125096417963505\n",
      "Epoch 9, Batch 200, Loss: 0.29076068744063377\n",
      "Epoch 9, Batch 300, Loss: 0.32359241545200346\n",
      "Epoch 9, Batch 400, Loss: 0.3061155427247286\n",
      "Epoch 9, Batch 500, Loss: 0.3152064011245966\n",
      "Epoch 9, Batch 600, Loss: 0.3282675515115261\n",
      "Epoch 9, Batch 700, Loss: 0.3268671342730522\n",
      "Epoch 9, Batch 800, Loss: 0.3023531760275364\n",
      "Epoch 9, Batch 900, Loss: 0.30711159750819206\n",
      "Epoch 10, Batch 100, Loss: 0.3090904550254345\n",
      "Epoch 10, Batch 200, Loss: 0.3168650867044926\n",
      "Epoch 10, Batch 300, Loss: 0.303637837395072\n",
      "Epoch 10, Batch 400, Loss: 0.3126003436744213\n",
      "Epoch 10, Batch 500, Loss: 0.30221504256129267\n",
      "Epoch 10, Batch 600, Loss: 0.3145657002925873\n",
      "Epoch 10, Batch 700, Loss: 0.3105102767795324\n",
      "Epoch 10, Batch 800, Loss: 0.31525281831622126\n",
      "Epoch 10, Batch 900, Loss: 0.316309482306242\n",
      "Epoch 11, Batch 100, Loss: 0.32202530533075335\n",
      "Epoch 11, Batch 200, Loss: 0.30163157925009726\n",
      "Epoch 11, Batch 300, Loss: 0.3091085213422775\n",
      "Epoch 11, Batch 400, Loss: 0.3045629778504372\n",
      "Epoch 11, Batch 500, Loss: 0.303197730332613\n",
      "Epoch 11, Batch 600, Loss: 0.3148697990179062\n",
      "Epoch 11, Batch 700, Loss: 0.3224017524719238\n",
      "Epoch 11, Batch 800, Loss: 0.3076178015768528\n",
      "Epoch 11, Batch 900, Loss: 0.30030939415097235\n",
      "Epoch 12, Batch 100, Loss: 0.3259188337624073\n",
      "Epoch 12, Batch 200, Loss: 0.31024032831192017\n",
      "Epoch 12, Batch 300, Loss: 0.30181661516427993\n",
      "Epoch 12, Batch 400, Loss: 0.29514432460069656\n",
      "Epoch 12, Batch 500, Loss: 0.31522967889904974\n",
      "Epoch 12, Batch 600, Loss: 0.31367195829749106\n",
      "Epoch 12, Batch 700, Loss: 0.3135968373715878\n",
      "Epoch 12, Batch 800, Loss: 0.2940421225130558\n",
      "Epoch 12, Batch 900, Loss: 0.29474847242236135\n",
      "Epoch 13, Batch 100, Loss: 0.3095252913236618\n",
      "Epoch 13, Batch 200, Loss: 0.30954035945236685\n",
      "Epoch 13, Batch 300, Loss: 0.31028016164898875\n",
      "Epoch 13, Batch 400, Loss: 0.3029529285430908\n",
      "Epoch 13, Batch 500, Loss: 0.2950434631109238\n",
      "Epoch 13, Batch 600, Loss: 0.29618426620960236\n",
      "Epoch 13, Batch 700, Loss: 0.29398771561682224\n",
      "Epoch 13, Batch 800, Loss: 0.32475008361041546\n",
      "Epoch 13, Batch 900, Loss: 0.311645727455616\n",
      "Epoch 14, Batch 100, Loss: 0.3080258750915527\n",
      "Epoch 14, Batch 200, Loss: 0.30987596288323405\n",
      "Epoch 14, Batch 300, Loss: 0.3052871537208557\n",
      "Epoch 14, Batch 400, Loss: 0.2961497484147549\n",
      "Epoch 14, Batch 500, Loss: 0.28624658107757567\n",
      "Epoch 14, Batch 600, Loss: 0.30066102802753447\n",
      "Epoch 14, Batch 700, Loss: 0.3213390783965588\n",
      "Epoch 14, Batch 800, Loss: 0.3014369370043278\n",
      "Epoch 14, Batch 900, Loss: 0.3059046008437872\n",
      "Epoch 15, Batch 100, Loss: 0.30577101811766627\n",
      "Epoch 15, Batch 200, Loss: 0.2917514616250992\n",
      "Epoch 15, Batch 300, Loss: 0.2905437118560076\n",
      "Epoch 15, Batch 400, Loss: 0.2953971467167139\n",
      "Epoch 15, Batch 500, Loss: 0.3133154284954071\n",
      "Epoch 15, Batch 600, Loss: 0.31694016575813294\n",
      "Epoch 15, Batch 700, Loss: 0.2860020892322063\n",
      "Epoch 15, Batch 800, Loss: 0.30606134846806526\n",
      "Epoch 15, Batch 900, Loss: 0.30929312579333784\n",
      "Epoch 16, Batch 100, Loss: 0.3070587070286274\n",
      "Epoch 16, Batch 200, Loss: 0.300750717818737\n",
      "Epoch 16, Batch 300, Loss: 0.2955416100472212\n",
      "Epoch 16, Batch 400, Loss: 0.29976914659142495\n",
      "Epoch 16, Batch 500, Loss: 0.2985364054143429\n",
      "Epoch 16, Batch 600, Loss: 0.3135956235229969\n",
      "Epoch 16, Batch 700, Loss: 0.28217613756656645\n",
      "Epoch 16, Batch 800, Loss: 0.2995829965174198\n",
      "Epoch 16, Batch 900, Loss: 0.3057937008142471\n",
      "Epoch 17, Batch 100, Loss: 0.30178331941366193\n",
      "Epoch 17, Batch 200, Loss: 0.2851385799050331\n",
      "Epoch 17, Batch 300, Loss: 0.2982922184467316\n",
      "Epoch 17, Batch 400, Loss: 0.30302110001444815\n",
      "Epoch 17, Batch 500, Loss: 0.3060649094730616\n",
      "Epoch 17, Batch 600, Loss: 0.29876293495297435\n",
      "Epoch 17, Batch 700, Loss: 0.2972715638577938\n",
      "Epoch 17, Batch 800, Loss: 0.3120455032587051\n",
      "Epoch 17, Batch 900, Loss: 0.289479640647769\n",
      "Epoch 18, Batch 100, Loss: 0.2830828410387039\n",
      "Epoch 18, Batch 200, Loss: 0.2920128688216209\n",
      "Epoch 18, Batch 300, Loss: 0.29622856304049494\n",
      "Epoch 18, Batch 400, Loss: 0.2998588360846043\n",
      "Epoch 18, Batch 500, Loss: 0.3017147771269083\n",
      "Epoch 18, Batch 600, Loss: 0.29574196599423885\n",
      "Epoch 18, Batch 700, Loss: 0.29255645103752614\n",
      "Epoch 18, Batch 800, Loss: 0.31795092068612574\n",
      "Epoch 18, Batch 900, Loss: 0.29438814833760263\n",
      "Epoch 19, Batch 100, Loss: 0.297095493376255\n",
      "Epoch 19, Batch 200, Loss: 0.29517980575561525\n",
      "Epoch 19, Batch 300, Loss: 0.2832771049439907\n",
      "Epoch 19, Batch 400, Loss: 0.2852932921051979\n",
      "Epoch 19, Batch 500, Loss: 0.28330448403954506\n",
      "Epoch 19, Batch 600, Loss: 0.30440587729215624\n",
      "Epoch 19, Batch 700, Loss: 0.3009946756064892\n",
      "Epoch 19, Batch 800, Loss: 0.3043997325003147\n",
      "Epoch 19, Batch 900, Loss: 0.3079823105037212\n",
      "Epoch 20, Batch 100, Loss: 0.28926872596144676\n",
      "Epoch 20, Batch 200, Loss: 0.2926298823952675\n",
      "Epoch 20, Batch 300, Loss: 0.2817799077183008\n",
      "Epoch 20, Batch 400, Loss: 0.2899366417527199\n",
      "Epoch 20, Batch 500, Loss: 0.29372873798012733\n",
      "Epoch 20, Batch 600, Loss: 0.3084116930514574\n",
      "Epoch 20, Batch 700, Loss: 0.2891926519572735\n",
      "Epoch 20, Batch 800, Loss: 0.29585934311151507\n",
      "Epoch 20, Batch 900, Loss: 0.31296879552304746\n",
      "Epoch 21, Batch 100, Loss: 0.2847350574284792\n",
      "Epoch 21, Batch 200, Loss: 0.3052657452225685\n",
      "Epoch 21, Batch 300, Loss: 0.3026378038525581\n",
      "Epoch 21, Batch 400, Loss: 0.297307545542717\n",
      "Epoch 21, Batch 500, Loss: 0.2988783046603203\n",
      "Epoch 21, Batch 600, Loss: 0.2886792442202568\n",
      "Epoch 21, Batch 700, Loss: 0.30071192488074305\n",
      "Epoch 21, Batch 800, Loss: 0.28502722695469856\n",
      "Epoch 21, Batch 900, Loss: 0.27649114578962325\n",
      "Epoch 22, Batch 100, Loss: 0.29477667815983294\n",
      "Epoch 22, Batch 200, Loss: 0.29454719871282575\n",
      "Epoch 22, Batch 300, Loss: 0.2829919261485338\n",
      "Epoch 22, Batch 400, Loss: 0.29120413452386856\n",
      "Epoch 22, Batch 500, Loss: 0.29059293180704115\n",
      "Epoch 22, Batch 600, Loss: 0.2792173457145691\n",
      "Epoch 22, Batch 700, Loss: 0.27783293202519416\n",
      "Epoch 22, Batch 800, Loss: 0.3082931560277939\n",
      "Epoch 22, Batch 900, Loss: 0.3031615661084652\n",
      "Epoch 23, Batch 100, Loss: 0.3004583844542503\n",
      "Epoch 23, Batch 200, Loss: 0.27725793853402136\n",
      "Epoch 23, Batch 300, Loss: 0.2850949611514807\n",
      "Epoch 23, Batch 400, Loss: 0.30261905536055567\n",
      "Epoch 23, Batch 500, Loss: 0.2941271065175533\n",
      "Epoch 23, Batch 600, Loss: 0.28609582856297494\n",
      "Epoch 23, Batch 700, Loss: 0.28500763669610024\n",
      "Epoch 23, Batch 800, Loss: 0.28660974122583865\n",
      "Epoch 23, Batch 900, Loss: 0.2892785529047251\n",
      "Epoch 24, Batch 100, Loss: 0.30013776749372484\n",
      "Epoch 24, Batch 200, Loss: 0.2879471924155951\n",
      "Epoch 24, Batch 300, Loss: 0.292420192360878\n",
      "Epoch 24, Batch 400, Loss: 0.2774896620213985\n",
      "Epoch 24, Batch 500, Loss: 0.2815787222236395\n",
      "Epoch 24, Batch 600, Loss: 0.2875372053682804\n",
      "Epoch 24, Batch 700, Loss: 0.2916298845410347\n",
      "Epoch 24, Batch 800, Loss: 0.291936522424221\n",
      "Epoch 24, Batch 900, Loss: 0.3017428557574749\n",
      "Epoch 25, Batch 100, Loss: 0.2777012173831463\n",
      "Epoch 25, Batch 200, Loss: 0.2769176161289215\n",
      "Epoch 25, Batch 300, Loss: 0.2912860342860222\n",
      "Epoch 25, Batch 400, Loss: 0.27743570059537886\n",
      "Epoch 25, Batch 500, Loss: 0.2770197628438473\n",
      "Epoch 25, Batch 600, Loss: 0.29347435042262077\n",
      "Epoch 25, Batch 700, Loss: 0.29129887230694296\n",
      "Epoch 25, Batch 800, Loss: 0.30678846158087253\n",
      "Epoch 25, Batch 900, Loss: 0.2926571600139141\n",
      "Epoch 26, Batch 100, Loss: 0.27196566164493563\n",
      "Epoch 26, Batch 200, Loss: 0.2944235424697399\n",
      "Epoch 26, Batch 300, Loss: 0.2777130737155676\n",
      "Epoch 26, Batch 400, Loss: 0.2794392803311348\n",
      "Epoch 26, Batch 500, Loss: 0.2851472672820091\n",
      "Epoch 26, Batch 600, Loss: 0.27878146193921566\n",
      "Epoch 26, Batch 700, Loss: 0.2903834407031536\n",
      "Epoch 26, Batch 800, Loss: 0.29260313034057617\n",
      "Epoch 26, Batch 900, Loss: 0.2950134763121605\n",
      "Epoch 27, Batch 100, Loss: 0.2785251331329346\n",
      "Epoch 27, Batch 200, Loss: 0.29169752582907676\n",
      "Epoch 27, Batch 300, Loss: 0.27912705108523367\n",
      "Epoch 27, Batch 400, Loss: 0.2951159682869911\n",
      "Epoch 27, Batch 500, Loss: 0.2707061228901148\n",
      "Epoch 27, Batch 600, Loss: 0.28523202568292616\n",
      "Epoch 27, Batch 700, Loss: 0.2786811556667089\n",
      "Epoch 27, Batch 800, Loss: 0.27839257061481476\n",
      "Epoch 27, Batch 900, Loss: 0.293773323148489\n",
      "Epoch 28, Batch 100, Loss: 0.28472302109003067\n",
      "Epoch 28, Batch 200, Loss: 0.28338293962180616\n",
      "Epoch 28, Batch 300, Loss: 0.27649206027388573\n",
      "Epoch 28, Batch 400, Loss: 0.28094091594219206\n",
      "Epoch 28, Batch 500, Loss: 0.285297734439373\n",
      "Epoch 28, Batch 600, Loss: 0.28228233754634857\n",
      "Epoch 28, Batch 700, Loss: 0.274109597876668\n",
      "Epoch 28, Batch 800, Loss: 0.27153713658452033\n",
      "Epoch 28, Batch 900, Loss: 0.28919741705060004\n",
      "Epoch 29, Batch 100, Loss: 0.28704859837889674\n",
      "Epoch 29, Batch 200, Loss: 0.28785503216087815\n",
      "Epoch 29, Batch 300, Loss: 0.28826006963849066\n",
      "Epoch 29, Batch 400, Loss: 0.2852834801375866\n",
      "Epoch 29, Batch 500, Loss: 0.27983761444687844\n",
      "Epoch 29, Batch 600, Loss: 0.28027003042399884\n",
      "Epoch 29, Batch 700, Loss: 0.272408394664526\n",
      "Epoch 29, Batch 800, Loss: 0.2782810371369123\n",
      "Epoch 29, Batch 900, Loss: 0.27346194848418237\n",
      "Epoch 30, Batch 100, Loss: 0.28292408093810084\n",
      "Epoch 30, Batch 200, Loss: 0.27450006470084193\n",
      "Epoch 30, Batch 300, Loss: 0.27813746824860575\n",
      "Epoch 30, Batch 400, Loss: 0.2745232093334198\n",
      "Epoch 30, Batch 500, Loss: 0.2726907369494438\n",
      "Epoch 30, Batch 600, Loss: 0.2801656945794821\n",
      "Epoch 30, Batch 700, Loss: 0.27940383553504944\n",
      "Epoch 30, Batch 800, Loss: 0.29541832908987997\n",
      "Epoch 30, Batch 900, Loss: 0.27704853907227517\n",
      "Epoch 31, Batch 100, Loss: 0.2830574432015419\n",
      "Epoch 31, Batch 200, Loss: 0.2868132504820824\n",
      "Epoch 31, Batch 300, Loss: 0.2697692541778088\n",
      "Epoch 31, Batch 400, Loss: 0.2773256927728653\n",
      "Epoch 31, Batch 500, Loss: 0.27322482772171497\n",
      "Epoch 31, Batch 600, Loss: 0.2828869478404522\n",
      "Epoch 31, Batch 700, Loss: 0.27258372932672503\n",
      "Epoch 31, Batch 800, Loss: 0.27843914806842807\n",
      "Epoch 31, Batch 900, Loss: 0.2792260143905878\n",
      "Epoch 32, Batch 100, Loss: 0.2667150619626045\n",
      "Epoch 32, Batch 200, Loss: 0.2795026117563248\n",
      "Epoch 32, Batch 300, Loss: 0.27835734918713567\n",
      "Epoch 32, Batch 400, Loss: 0.2754048272967339\n",
      "Epoch 32, Batch 500, Loss: 0.2743066561222076\n",
      "Epoch 32, Batch 600, Loss: 0.28015368930995466\n",
      "Epoch 32, Batch 700, Loss: 0.2718606520071626\n",
      "Epoch 32, Batch 800, Loss: 0.2726541010290384\n",
      "Epoch 32, Batch 900, Loss: 0.2851793631911278\n",
      "Epoch 33, Batch 100, Loss: 0.2841924737393856\n",
      "Epoch 33, Batch 200, Loss: 0.267279256246984\n",
      "Epoch 33, Batch 300, Loss: 0.27771181710064413\n",
      "Epoch 33, Batch 400, Loss: 0.27061006546020505\n",
      "Epoch 33, Batch 500, Loss: 0.2773312934488058\n",
      "Epoch 33, Batch 600, Loss: 0.2636622367799282\n",
      "Epoch 33, Batch 700, Loss: 0.2748123283684254\n",
      "Epoch 33, Batch 800, Loss: 0.272638224363327\n",
      "Epoch 33, Batch 900, Loss: 0.28564456924796106\n",
      "Epoch 34, Batch 100, Loss: 0.2759752216935158\n",
      "Epoch 34, Batch 200, Loss: 0.27577136784791945\n",
      "Epoch 34, Batch 300, Loss: 0.27618101753294466\n",
      "Epoch 34, Batch 400, Loss: 0.27012063562870026\n",
      "Epoch 34, Batch 500, Loss: 0.2782493785768747\n",
      "Epoch 34, Batch 600, Loss: 0.27091454580426216\n",
      "Epoch 34, Batch 700, Loss: 0.2792065817117691\n",
      "Epoch 34, Batch 800, Loss: 0.26980481192469596\n",
      "Epoch 34, Batch 900, Loss: 0.2663405796140432\n",
      "Epoch 35, Batch 100, Loss: 0.2734323237836361\n",
      "Epoch 35, Batch 200, Loss: 0.2710966567695141\n",
      "Epoch 35, Batch 300, Loss: 0.2658947939425707\n",
      "Epoch 35, Batch 400, Loss: 0.2702408044040203\n",
      "Epoch 35, Batch 500, Loss: 0.2793753407895565\n",
      "Epoch 35, Batch 600, Loss: 0.2705327881872654\n",
      "Epoch 35, Batch 700, Loss: 0.27283943340182304\n",
      "Epoch 35, Batch 800, Loss: 0.2709554833173752\n",
      "Epoch 35, Batch 900, Loss: 0.27433537811040876\n",
      "Epoch 36, Batch 100, Loss: 0.26174241460859776\n",
      "Epoch 36, Batch 200, Loss: 0.2731973013281822\n",
      "Epoch 36, Batch 300, Loss: 0.2552375399321318\n",
      "Epoch 36, Batch 400, Loss: 0.26610309064388277\n",
      "Epoch 36, Batch 500, Loss: 0.2712190616875887\n",
      "Epoch 36, Batch 600, Loss: 0.28600130930542944\n",
      "Epoch 36, Batch 700, Loss: 0.27551222801208497\n",
      "Epoch 36, Batch 800, Loss: 0.280823300331831\n",
      "Epoch 36, Batch 900, Loss: 0.27530773788690566\n",
      "Epoch 37, Batch 100, Loss: 0.26308650597929956\n",
      "Epoch 37, Batch 200, Loss: 0.27495302714407444\n",
      "Epoch 37, Batch 300, Loss: 0.2790819092839956\n",
      "Epoch 37, Batch 400, Loss: 0.27018252152949573\n",
      "Epoch 37, Batch 500, Loss: 0.26720473036170006\n",
      "Epoch 37, Batch 600, Loss: 0.26399538092315195\n",
      "Epoch 37, Batch 700, Loss: 0.264784959256649\n",
      "Epoch 37, Batch 800, Loss: 0.27072081238031387\n",
      "Epoch 37, Batch 900, Loss: 0.278098326921463\n",
      "Epoch 38, Batch 100, Loss: 0.2736900866776705\n",
      "Epoch 38, Batch 200, Loss: 0.2629479437321425\n",
      "Epoch 38, Batch 300, Loss: 0.2736478826403618\n",
      "Epoch 38, Batch 400, Loss: 0.2673621343076229\n",
      "Epoch 38, Batch 500, Loss: 0.26699187479913233\n",
      "Epoch 38, Batch 600, Loss: 0.2723194439709187\n",
      "Epoch 38, Batch 700, Loss: 0.2712274505198002\n",
      "Epoch 38, Batch 800, Loss: 0.26464086256921293\n",
      "Epoch 38, Batch 900, Loss: 0.25871919877827165\n",
      "Epoch 39, Batch 100, Loss: 0.2564611544460058\n",
      "Epoch 39, Batch 200, Loss: 0.25851955384016034\n",
      "Epoch 39, Batch 300, Loss: 0.24690387107431888\n",
      "Epoch 39, Batch 400, Loss: 0.2744798919558525\n",
      "Epoch 39, Batch 500, Loss: 0.27520149283111095\n",
      "Epoch 39, Batch 600, Loss: 0.2691405531018972\n",
      "Epoch 39, Batch 700, Loss: 0.2673142120242119\n",
      "Epoch 39, Batch 800, Loss: 0.28466811336576936\n",
      "Epoch 39, Batch 900, Loss: 0.26597957298159597\n",
      "Epoch 40, Batch 100, Loss: 0.2711142464727163\n",
      "Epoch 40, Batch 200, Loss: 0.27181812196969984\n",
      "Epoch 40, Batch 300, Loss: 0.26356531381607057\n",
      "Epoch 40, Batch 400, Loss: 0.27057402312755585\n",
      "Epoch 40, Batch 500, Loss: 0.25110707357525824\n",
      "Epoch 40, Batch 600, Loss: 0.2535999054461718\n",
      "Epoch 40, Batch 700, Loss: 0.27224842831492424\n",
      "Epoch 40, Batch 800, Loss: 0.2637838587164879\n",
      "Epoch 40, Batch 900, Loss: 0.2631188533455133\n",
      "Epoch 41, Batch 100, Loss: 0.2509239276498556\n",
      "Epoch 41, Batch 200, Loss: 0.27084826953709124\n",
      "Epoch 41, Batch 300, Loss: 0.2849003404378891\n",
      "Epoch 41, Batch 400, Loss: 0.2608041212707758\n",
      "Epoch 41, Batch 500, Loss: 0.2654294396936894\n",
      "Epoch 41, Batch 600, Loss: 0.2719836799800396\n",
      "Epoch 41, Batch 700, Loss: 0.2540910833328962\n",
      "Epoch 41, Batch 800, Loss: 0.26631341442465783\n",
      "Epoch 41, Batch 900, Loss: 0.2607773418724537\n",
      "Epoch 42, Batch 100, Loss: 0.2644736671447754\n",
      "Epoch 42, Batch 200, Loss: 0.2568695729970932\n",
      "Epoch 42, Batch 300, Loss: 0.2590792839974165\n",
      "Epoch 42, Batch 400, Loss: 0.2750073915719986\n",
      "Epoch 42, Batch 500, Loss: 0.2531953698396683\n",
      "Epoch 42, Batch 600, Loss: 0.2713887044787407\n",
      "Epoch 42, Batch 700, Loss: 0.26593762561678885\n",
      "Epoch 42, Batch 800, Loss: 0.25016778089106084\n",
      "Epoch 42, Batch 900, Loss: 0.2686389856785536\n",
      "Epoch 43, Batch 100, Loss: 0.2520181557536125\n",
      "Epoch 43, Batch 200, Loss: 0.2559537509083748\n",
      "Epoch 43, Batch 300, Loss: 0.275427031815052\n",
      "Epoch 43, Batch 400, Loss: 0.265916281118989\n",
      "Epoch 43, Batch 500, Loss: 0.25930192969739435\n",
      "Epoch 43, Batch 600, Loss: 0.26580636389553547\n",
      "Epoch 43, Batch 700, Loss: 0.2550434888899326\n",
      "Epoch 43, Batch 800, Loss: 0.26482003219425676\n",
      "Epoch 43, Batch 900, Loss: 0.2745093728601933\n",
      "Epoch 44, Batch 100, Loss: 0.26833087906241415\n",
      "Epoch 44, Batch 200, Loss: 0.25964788742363454\n",
      "Epoch 44, Batch 300, Loss: 0.2679819515347481\n",
      "Epoch 44, Batch 400, Loss: 0.24048760041594505\n",
      "Epoch 44, Batch 500, Loss: 0.2663238290697336\n",
      "Epoch 44, Batch 600, Loss: 0.25913314923644065\n",
      "Epoch 44, Batch 700, Loss: 0.2638773509860039\n",
      "Epoch 44, Batch 800, Loss: 0.2594832208007574\n",
      "Epoch 44, Batch 900, Loss: 0.2624451668560505\n",
      "Epoch 45, Batch 100, Loss: 0.2591531389951706\n",
      "Epoch 45, Batch 200, Loss: 0.2585389000177383\n",
      "Epoch 45, Batch 300, Loss: 0.26301698096096515\n",
      "Epoch 45, Batch 400, Loss: 0.25418964453041554\n",
      "Epoch 45, Batch 500, Loss: 0.2678536827862263\n",
      "Epoch 45, Batch 600, Loss: 0.2593526330590248\n",
      "Epoch 45, Batch 700, Loss: 0.2706818453967571\n",
      "Epoch 45, Batch 800, Loss: 0.2642172206938267\n",
      "Epoch 45, Batch 900, Loss: 0.2492286454886198\n",
      "Epoch 46, Batch 100, Loss: 0.25618202656507494\n",
      "Epoch 46, Batch 200, Loss: 0.2628568307310343\n",
      "Epoch 46, Batch 300, Loss: 0.25973517686128617\n",
      "Epoch 46, Batch 400, Loss: 0.24692701138556003\n",
      "Epoch 46, Batch 500, Loss: 0.2772072169929743\n",
      "Epoch 46, Batch 600, Loss: 0.26028555549681187\n",
      "Epoch 46, Batch 700, Loss: 0.26101890206336975\n",
      "Epoch 46, Batch 800, Loss: 0.2590694611519575\n",
      "Epoch 46, Batch 900, Loss: 0.23304451361298562\n",
      "Epoch 47, Batch 100, Loss: 0.26398616813123227\n",
      "Epoch 47, Batch 200, Loss: 0.2594203218817711\n",
      "Epoch 47, Batch 300, Loss: 0.25028549663722516\n",
      "Epoch 47, Batch 400, Loss: 0.2713558802008629\n",
      "Epoch 47, Batch 500, Loss: 0.2464768522232771\n",
      "Epoch 47, Batch 600, Loss: 0.25259085446596147\n",
      "Epoch 47, Batch 700, Loss: 0.2452726925909519\n",
      "Epoch 47, Batch 800, Loss: 0.25486804969608784\n",
      "Epoch 47, Batch 900, Loss: 0.2580821627378464\n",
      "Epoch 48, Batch 100, Loss: 0.25395118907094\n",
      "Epoch 48, Batch 200, Loss: 0.2507162367552519\n",
      "Epoch 48, Batch 300, Loss: 0.262276645898819\n",
      "Epoch 48, Batch 400, Loss: 0.24217376463115214\n",
      "Epoch 48, Batch 500, Loss: 0.24833875462412835\n",
      "Epoch 48, Batch 600, Loss: 0.2715384075790644\n",
      "Epoch 48, Batch 700, Loss: 0.2539422361552715\n",
      "Epoch 48, Batch 800, Loss: 0.23621470108628273\n",
      "Epoch 48, Batch 900, Loss: 0.2809226748347282\n",
      "Epoch 49, Batch 100, Loss: 0.26098716877400874\n",
      "Epoch 49, Batch 200, Loss: 0.2479981230944395\n",
      "Epoch 49, Batch 300, Loss: 0.2639836251735687\n",
      "Epoch 49, Batch 400, Loss: 0.2660668792575598\n",
      "Epoch 49, Batch 500, Loss: 0.2565779972821474\n",
      "Epoch 49, Batch 600, Loss: 0.23772226609289646\n",
      "Epoch 49, Batch 700, Loss: 0.2551203645020723\n",
      "Epoch 49, Batch 800, Loss: 0.2422673636674881\n",
      "Epoch 49, Batch 900, Loss: 0.24870404280722141\n",
      "Epoch 50, Batch 100, Loss: 0.25166197776794436\n",
      "Epoch 50, Batch 200, Loss: 0.24760902009904384\n",
      "Epoch 50, Batch 300, Loss: 0.2534452599287033\n",
      "Epoch 50, Batch 400, Loss: 0.2531000815331936\n",
      "Epoch 50, Batch 500, Loss: 0.2529237844049931\n",
      "Epoch 50, Batch 600, Loss: 0.261084473207593\n",
      "Epoch 50, Batch 700, Loss: 0.25645166769623756\n",
      "Epoch 50, Batch 800, Loss: 0.25190603189170363\n",
      "Epoch 50, Batch 900, Loss: 0.251910592764616\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01) \n",
    "\n",
    "# Training the neural network\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "RNMCpk60EaXr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8734%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on test set: { correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "J2GkmLeQEeZV"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 27\n",
    "test_image, test_label = test_dataset[image_index]\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    output = model(test_image.unsqueeze(0))\n",
    "    _, predicted_label = torch.max(output, 1)\n",
    "\n",
    "test_image_numpy = test_image.squeeze().numpy()\n",
    "\n",
    "plt.imshow(test_image_numpy, cmap='gray')\n",
    "plt.title(f'Predicted Label: {predicted_label.item()}, Actual Label: {test_label}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoypxOXgGjuC"
   },
   "source": [
    "Notes for Part 1\n",
    "\n",
    "1. Activation fucntion:\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(28*28, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.relu(self.fc1(x))  # Change activation function here\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "2. loss function and optimizer\n",
    "\n",
    "model = Net()\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Change loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "3. ~adding a dropout layer\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(28*28, 128)\n",
    "        self.dropout = torch.nn.Dropout(0.2)  # Add a Dropout layer here\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Apply Dropout\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "4. model configurations / epochs\n",
    "\n",
    "epochs = 10  # Change number of epochs\n",
    "for epoch in range(epochs):\n",
    "    # Training loop\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Training steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5nxrEoAHAUX"
   },
   "source": [
    "## CNN Implimentation with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccRJi8VXH3_O"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k41uN-aAIH6Y"
   },
   "outputs": [],
   "source": [
    "# Mapping the labels for the MNIST dataset\n",
    "labels_map = {\n",
    "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n",
    "    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_MUVyZ5Iksr"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEoqWEFz5Ms-"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eX_tkHuwEK7B"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7l92S_RxJZTm"
   },
   "outputs": [],
   "source": [
    "def create_model(num_layers=2, units_per_layer=128, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28)))\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        model.add(Dense(units_per_layer, activation=activation))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPfHtKytJd9Q"
   },
   "outputs": [],
   "source": [
    "num_layers = 6\n",
    "units_per_layer = 256\n",
    "activation = 'relu'\n",
    "learning_rate = 0.01\n",
    "epochs = 75\n",
    "batch_size = 48\n",
    "\n",
    "# Create the model\n",
    "model = create_model(num_layers=num_layers, units_per_layer=units_per_layer, activation=activation)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=SGD(learning_rate=learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlPkc9auJkET"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ig5GXhcG5fy6"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJa4Lf76KZDM"
   },
   "outputs": [],
   "source": [
    "image_index = 27\n",
    "\n",
    "# Extract the test image and label\n",
    "test_image = x_test[image_index]\n",
    "test_label = np.argmax(y_test[image_index])\n",
    "\n",
    "# Reshape the test image for prediction (Keras expects a batch dimension)\n",
    "test_image_reshaped = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "# Make predictions on the test image\n",
    "predicted_label = np.argmax(model.predict(test_image_reshaped), axis=-1)\n",
    "\n",
    "# Plot the test image with predicted and actual labels\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "plt.title(f'Predicted Label: {predicted_label[0]}, Actual Label: {test_label}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cc8F7Lo_AOII"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(16, (5, 5), activation='sigmoid', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='tanh'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='softmax'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=25)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images.reshape(-1, 28, 28, 1), test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nK1xXT5W7cMS"
   },
   "source": [
    "## AUTOMATED TUNING (EXETENDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIeVei_C8sVB"
   },
   "outputs": [],
   "source": [
    "https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "dl_proj2",
   "language": "python",
   "name": "dl_proj2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
